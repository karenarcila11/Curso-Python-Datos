{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06 ¬∑ Manejo de caracteres y archivos\n",
    "\n",
    "**M√≥dulo I ‚Äî Fundamentos**\n",
    "\n",
    "## Objetivos:\n",
    "- Comprender la codificaci√≥n de caracteres y su importancia en datos m√©dicos\n",
    "- Resolver problemas comunes con tildes, √± y caracteres especiales\n",
    "- Manejar diferentes formatos de archivo y sistemas operativos\n",
    "- Implementar soluciones robustas para intercambio de datos\n",
    "- Aplicar buenas pr√°cticas en sistemas hospitalarios\n",
    "\n",
    "## Contexto Real - ¬øPor qu√© es crucial en el sector salud?\n",
    "\n",
    "En COMFENALCO y el sistema de salud colombiano:\n",
    "- **Nombres de pacientes**: Mar√≠a Jos√©, Jos√© √Ångel, Nu√±ez, Pe√±a\n",
    "- **Reportes a Supersalud**: Deben mantener caracteres originales\n",
    "- **Intercambio con ADRES**: Sistemas con diferentes codificaciones\n",
    "- **Bases de datos hist√≥ricas**: Datos en Latin1, nuevos en UTF-8\n",
    "- **Errores costosos**: Un nombre mal codificado = paciente no encontrado\n",
    "\n",
    "## √çndice:\n",
    "1. Fundamentos de codificaci√≥n de caracteres\n",
    "2. Problemas comunes en datos m√©dicos colombianos\n",
    "3. Detecci√≥n autom√°tica de encoding\n",
    "4. Conversi√≥n entre formatos\n",
    "5. Manejo robusto de archivos\n",
    "6. Casos de error y soluciones\n",
    "7. Implementaci√≥n en sistemas EPS\n",
    "8. Ejercicios con datos reales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Fundamentos de codificaci√≥n de caracteres\n",
    "\n",
    "### ü§î Pregunta reflexiva para el grupo:\n",
    "**¬øAlguna vez han tenido problemas con nombres que aparecen como \"Jos√©\" en lugar de \"Jos√©\" en sus sistemas?**\n",
    "\n",
    "### Contexto Real - Problema t√≠pico en EPS:\n",
    "Un paciente se registra como \"Jos√© √Ångel Mu√±oz\" pero en el sistema aparece como:\n",
    "- Sistema A: \"Jos√© √Ångel Mu√±oz\" \n",
    "- Sistema B: \"Jos √Ångel Muoz\"\n",
    "- Reporte Excel: \"Jos√© √ÉÔøΩngel Mu√É¬±oz\"\n",
    "\n",
    "**Resultado**: El mismo paciente parece ser 3 personas diferentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparaci√≥n del entorno\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import chardet  # Para detecci√≥n autom√°tica de encoding\n",
    "import codecs\n",
    "import json\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Librer√≠as importadas exitosamente\")\n",
    "print(\"Configurando entorno para manejo de caracteres especiales...\")\n",
    "\n",
    "# Crear estructura de carpetas\n",
    "BASE_DIR = Path.cwd()\n",
    "DATA_DIR = BASE_DIR / \"data\" / \"encoding_examples\"\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Carpeta de trabajo: {DATA_DIR}\")\n",
    "print(\"Listo para comenzar con ejercicios de codificaci√≥n!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demostrar el problema con un ejemplo real\n",
    "def demostrar_problema_encoding():\n",
    "    \"\"\"\n",
    "    Demuestra c√≥mo los mismos caracteres se ven diferentes seg√∫n la codificaci√≥n.\n",
    "    \"\"\"\n",
    "    # Nombres t√≠picos colombianos con caracteres especiales\n",
    "    nombres_colombia = [\n",
    "        \"Mar√≠a Jos√© P√©rez\",\n",
    "        \"Jos√© √Ångel Mu√±oz\", \n",
    "        \"Sof√≠a Hern√°ndez\",\n",
    "        \"Nicol√°s Pe√±a\",\n",
    "        \"Andr√©s N√∫√±ez\"\n",
    "    ]\n",
    "    \n",
    "    print(\"DEMOSTRACI√ìN: El mismo nombre en diferentes codificaciones\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    nombre_ejemplo = \"Jos√© √Ångel Mu√±oz\"\n",
    "    print(f\"Nombre original: {nombre_ejemplo}\")\n",
    "    print()\n",
    "    \n",
    "    # Mostrar c√≥mo se ve en diferentes encodings\n",
    "    encodings_comunes = ['utf-8', 'latin1', 'cp1252', 'ascii']\n",
    "    \n",
    "    for encoding in encodings_comunes:\n",
    "        try:\n",
    "            # Codificar y decodificar para simular el problema\n",
    "            bytes_encoded = nombre_ejemplo.encode('utf-8')\n",
    "            \n",
    "            if encoding == 'ascii':\n",
    "                # ASCII no puede manejar caracteres especiales\n",
    "                resultado = \"ERROR: No se pueden procesar caracteres especiales\"\n",
    "            else:\n",
    "                # Decodificar con encoding incorrecto\n",
    "                resultado = bytes_encoded.decode(encoding, errors='replace')\n",
    "            \n",
    "            print(f\"{encoding.upper():<8}: {resultado}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"{encoding.upper():<8}: ERROR - {str(e)}\")\n",
    "    \n",
    "    return nombres_colombia\n",
    "\n",
    "nombres_test = demostrar_problema_encoding()\n",
    "\n",
    "# CHECKPOINT 1\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"‚úÖ CHECKPOINT 1: ¬øPueden ver las diferencias en los nombres?\")\n",
    "print(\"üë®‚Äçüè´ Instructor: Verifiquemos que todos vean los resultados\")\n",
    "print(\"ü§î ¬øCu√°l creen que es la codificaci√≥n correcta para nombres colombianos?\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Problemas comunes en datos m√©dicos colombianos\n",
    "\n",
    "### Contexto Real - Casos que veremos en COMFENALCO:\n",
    "1. **Importar CSV desde Excel**: Latin1 vs UTF-8\n",
    "2. **Reportes de MinSalud**: Diferentes sistemas, diferentes encodings\n",
    "3. **Bases de datos legacy**: Datos hist√≥ricos en ASCII extendido\n",
    "4. **APIs modernas**: UTF-8 por defecto\n",
    "5. **Archivos de intercambio**: RIPS, BDUA con caracteres especiales\n",
    "\n",
    "### ü§î Pregunta reflexiva:\n",
    "**¬øHan notado que algunos reportes muestran caracteres extra√±os cuando los abren en Excel?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear dataset con problemas t√≠picos de encoding\n",
    "def crear_datos_problema_encoding():\n",
    "    \"\"\"\n",
    "    Crea archivos con diferentes encodings para simular problemas reales.\n",
    "    \"\"\"\n",
    "    # Datos t√≠picos de una EPS con caracteres problem√°ticos\n",
    "    datos_eps = {\n",
    "        'id_afiliado': [1001, 1002, 1003, 1004, 1005],\n",
    "        'nombres': [\n",
    "            'Mar√≠a Jos√©',\n",
    "            'Jos√© √Ångel', \n",
    "            'Ana Sof√≠a',\n",
    "            'Luis Hern√°n',\n",
    "            'Nicol√°s'\n",
    "        ],\n",
    "        'apellidos': [\n",
    "            'P√©rez Garc√≠a',\n",
    "            'Mu√±oz L√≥pez',\n",
    "            'Hern√°ndez Pe√±a',\n",
    "            'N√∫√±ez V√°squez',\n",
    "            'G√≥mez S√°nchez'\n",
    "        ],\n",
    "        'municipio': [\n",
    "            'Bogot√° D.C.',\n",
    "            'Medell√≠n',\n",
    "            'Cali',\n",
    "            'Pereira', \n",
    "            'Manizales'\n",
    "        ],\n",
    "        'diagnostico': [\n",
    "            'Hipertensi√≥n arterial',\n",
    "            'Diabetes mellitus',\n",
    "            'Cefalea tensional',\n",
    "            'Lumbalgia mec√°nica',\n",
    "            'Rinitis al√©rgica'\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    df_eps = pd.DataFrame(datos_eps)\n",
    "    \n",
    "    print(\"Creando archivos con diferentes encodings...\")\n",
    "    print(\"(Esto simula archivos que llegan de diferentes sistemas)\")\n",
    "    \n",
    "    # Archivo 1: UTF-8 (correcto)\n",
    "    archivo_utf8 = DATA_DIR / \"afiliados_utf8.csv\"\n",
    "    df_eps.to_csv(archivo_utf8, index=False, encoding='utf-8')\n",
    "    \n",
    "    # Archivo 2: Latin1 (com√∫n en sistemas legacy)\n",
    "    archivo_latin1 = DATA_DIR / \"afiliados_latin1.csv\"\n",
    "    df_eps.to_csv(archivo_latin1, index=False, encoding='latin1')\n",
    "    \n",
    "    # Archivo 3: CP1252 (Windows espa√±ol)\n",
    "    archivo_cp1252 = DATA_DIR / \"afiliados_cp1252.csv\"\n",
    "    df_eps.to_csv(archivo_cp1252, index=False, encoding='cp1252')\n",
    "    \n",
    "    archivos_creados = [\n",
    "        (archivo_utf8, 'utf-8', 'Sistema moderno (recomendado)'),\n",
    "        (archivo_latin1, 'latin1', 'Sistema legacy hospitalario'),\n",
    "        (archivo_cp1252, 'cp1252', 'Excel Windows espa√±ol')\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nArchivos creados:\")\n",
    "    for archivo, encoding, descripcion in archivos_creados:\n",
    "        tama√±o = archivo.stat().st_size / 1024\n",
    "        print(f\"  ‚úÖ {archivo.name:<25} ({encoding:<8}) - {descripcion}\")\n",
    "    \n",
    "    return df_eps, archivos_creados\n",
    "\n",
    "df_original, archivos_test = crear_datos_problema_encoding()\n",
    "print(f\"\\nDatos originales:\")\n",
    "display(df_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demostrar qu√© pasa al abrir con encoding incorrecto\n",
    "def demostrar_lectura_incorrecta():\n",
    "    \"\"\"\n",
    "    Muestra el ERROR com√∫n: abrir archivo con encoding incorrecto.\n",
    "    \"\"\"\n",
    "    print(\"DEMOSTRACI√ìN: ¬øQu√© pasa al leer con encoding incorrecto?\")\n",
    "    print(\"(Esto es lo que pasa cuando Excel abre un archivo UTF-8)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    archivo_utf8 = DATA_DIR / \"afiliados_utf8.csv\"\n",
    "    \n",
    "    # Lectura correcta (UTF-8)\n",
    "    print(\"1. LECTURA CORRECTA (UTF-8):\")\n",
    "    df_correcto = pd.read_csv(archivo_utf8, encoding='utf-8')\n",
    "    print(\"Nombres:\", list(df_correcto['nombres']))\n",
    "    \n",
    "    # Lectura incorrecta (Latin1)\n",
    "    print(\"\\n2. LECTURA INCORRECTA (Latin1):\")\n",
    "    print(\"(Simula abrir archivo UTF-8 como si fuera Latin1)\")\n",
    "    try:\n",
    "        df_incorrecto = pd.read_csv(archivo_utf8, encoding='latin1')\n",
    "        print(\"Nombres:\", list(df_incorrecto['nombres']))\n",
    "        print(\"üëÄ ¬øNotan la diferencia? Los acentos se ven raros.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    \n",
    "    return df_correcto, df_incorrecto\n",
    "\n",
    "df_bien, df_mal = demostrar_lectura_incorrecta()\n",
    "\n",
    "# CHECKPOINT 2\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"‚úÖ CHECKPOINT 2: Comparaci√≥n de lecturas\")\n",
    "print(\"üë®‚Äçüè´ ¬øTodos pueden ver la diferencia en los nombres?\")\n",
    "print(\"ü§î En su trabajo, ¬øhan visto nombres con caracteres extra√±os?\")\n",
    "print(\"üí° Esto explica por qu√© a veces los reportes se ven mal en Excel\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Detecci√≥n autom√°tica de encoding\n",
    "\n",
    "### Contexto Real - Situaci√≥n t√≠pica en COMFENALCO:\n",
    "**Llega un archivo de otra IPS con nombres que no se ven bien. ¬øC√≥mo saber qu√© encoding usar?**\n",
    "\n",
    "### üîß Soluci√≥n pr√°ctica:\n",
    "Usar la librer√≠a `chardet` para detectar autom√°ticamente el encoding.\n",
    "\n",
    "### ü§î Pregunta reflexiva:\n",
    "**¬øPrefieren adivinar el encoding o que el sistema lo detecte autom√°ticamente?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n para detectar encoding autom√°ticamente\n",
    "def detectar_encoding_archivo(ruta_archivo):\n",
    "    \"\"\"\n",
    "    Detecta autom√°ticamente la codificaci√≥n de un archivo.\n",
    "    √ötil cuando llegan archivos de sistemas externos.\n",
    "    \"\"\"\n",
    "    print(f\"\\nAnalizando archivo: {ruta_archivo.name}\")\n",
    "    \n",
    "    # Leer una muestra del archivo\n",
    "    with open(ruta_archivo, 'rb') as archivo:\n",
    "        muestra = archivo.read(10000)  # Primeros 10KB\n",
    "    \n",
    "    # Detectar encoding\n",
    "    resultado = chardet.detect(muestra)\n",
    "    \n",
    "    print(f\"  Encoding detectado: {resultado['encoding']}\")\n",
    "    print(f\"  Confianza: {resultado['confidence']*100:.1f}%\")\n",
    "    print(f\"  Lenguaje: {resultado.get('language', 'No detectado')}\")\n",
    "    \n",
    "    return resultado['encoding'], resultado['confidence']\n",
    "\n",
    "# Detectar encoding de todos nuestros archivos de prueba\n",
    "print(\"DETECCI√ìN AUTOM√ÅTICA DE ENCODING\")\n",
    "print(\"=\"*50)\n",
    "print(\"(Esto es lo que har√≠amos con archivos de origen desconocido)\")\n",
    "\n",
    "resultados_deteccion = {}\n",
    "for archivo_path, encoding_real, descripcion in archivos_test:\n",
    "    encoding_detectado, confianza = detectar_encoding_archivo(archivo_path)\n",
    "    resultados_deteccion[archivo_path.name] = {\n",
    "        'real': encoding_real,\n",
    "        'detectado': encoding_detectado,\n",
    "        'confianza': confianza\n",
    "    }\n",
    "    print(f\"  ‚úÖ Encoding real: {encoding_real} | Detectado: {encoding_detectado}\")\n",
    "    print(f\"      Coincidencia: {'S√ç' if encoding_real == encoding_detectado else 'NO'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n robusta para leer archivos con encoding autom√°tico\n",
    "def leer_csv_robusto(ruta_archivo, mostrar_proceso=True):\n",
    "    \"\"\"\n",
    "    Lee un archivo CSV detectando autom√°ticamente el encoding.\n",
    "    Esta funci√≥n es la que usar√≠amos en producci√≥n en COMFENALCO.\n",
    "    \"\"\"\n",
    "    if mostrar_proceso:\n",
    "        print(f\"\\nüìÇ Abriendo archivo: {ruta_archivo.name}\")\n",
    "    \n",
    "    # Paso 1: Detectar encoding\n",
    "    with open(ruta_archivo, 'rb') as archivo:\n",
    "        muestra = archivo.read(10000)\n",
    "    \n",
    "    deteccion = chardet.detect(muestra)\n",
    "    encoding_detectado = deteccion['encoding']\n",
    "    confianza = deteccion['confidence']\n",
    "    \n",
    "    if mostrar_proceso:\n",
    "        print(f\"   üîç Encoding detectado: {encoding_detectado} ({confianza*100:.1f}% confianza)\")\n",
    "    \n",
    "    # Paso 2: Leer con encoding detectado\n",
    "    try:\n",
    "        df = pd.read_csv(ruta_archivo, encoding=encoding_detectado)\n",
    "        if mostrar_proceso:\n",
    "            print(f\"   ‚úÖ Archivo le√≠do exitosamente: {df.shape[0]} filas, {df.shape[1]} columnas\")\n",
    "        return df, encoding_detectado\n",
    "        \n",
    "    except Exception as e:\n",
    "        if mostrar_proceso:\n",
    "            print(f\"   ‚ùå Error con encoding detectado: {e}\")\n",
    "            print(f\"   üîÑ Intentando con UTF-8...\")\n",
    "        \n",
    "        # Paso 3: Fallback a UTF-8\n",
    "        try:\n",
    "            df = pd.read_csv(ruta_archivo, encoding='utf-8')\n",
    "            if mostrar_proceso:\n",
    "                print(f\"   ‚úÖ Le√≠do con UTF-8: {df.shape[0]} filas, {df.shape[1]} columnas\")\n",
    "            return df, 'utf-8'\n",
    "        except:\n",
    "            # Paso 4: Fallback final con errors='replace'\n",
    "            if mostrar_proceso:\n",
    "                print(f\"   üîÑ √öltimo intento con reemplazo de caracteres...\")\n",
    "            df = pd.read_csv(ruta_archivo, encoding='utf-8', errors='replace')\n",
    "            if mostrar_proceso:\n",
    "                print(f\"   ‚ö†Ô∏è  Le√≠do con reemplazo de caracteres: {df.shape[0]} filas\")\n",
    "            return df, 'utf-8-replace'\n",
    "\n",
    "# Probar la funci√≥n robusta con todos nuestros archivos\n",
    "print(\"\\nPROBANDO FUNCI√ìN ROBUSTA DE LECTURA\")\n",
    "print(\"=\"*50)\n",
    "print(\"(Esta ser√≠a nuestra funci√≥n est√°ndar para COMFENALCO)\")\n",
    "\n",
    "dataframes_leidos = []\n",
    "for archivo_path, encoding_real, descripcion in archivos_test:\n",
    "    df, encoding_usado = leer_csv_robusto(archivo_path)\n",
    "    dataframes_leidos.append((archivo_path.name, df, encoding_usado))\n",
    "    \n",
    "    # Mostrar una muestra de los nombres para verificar\n",
    "    print(f\"   üë§ Muestra de nombres: {df['nombres'].iloc[0]}, {df['nombres'].iloc[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Conversi√≥n entre formatos\n",
    "\n",
    "### Contexto Real - Caso pr√°ctico COMFENALCO:\n",
    "**Escenario**: Tenemos archivos hist√≥ricos en Latin1 y necesitamos migrarlos a UTF-8 para el nuevo sistema.\n",
    "\n",
    "### ü§î Pregunta reflexiva:\n",
    "**¬øHan tenido que migrar datos de un sistema viejo a uno nuevo? ¬øQu√© problemas encontraron?**\n",
    "\n",
    "### ‚ö†Ô∏è Caso de error com√∫n:\n",
    "**Error t√≠pico**: Convertir directamente sin verificar, perdiendo caracteres especiales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECKPOINT 3\n",
    "print(\"‚úÖ CHECKPOINT 3: Verificaci√≥n antes de conversi√≥n\")\n",
    "print(\"üë®‚Äçüè´ ¬øTodos pudieron leer correctamente los tres archivos?\")\n",
    "print(\"ü§î ¬øNotan alguna diferencia en la calidad de los nombres?\")\n",
    "print(\"üíº Conexi√≥n EPS: As√≠ procesar√≠amos archivos de diferentes IPS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Funci√≥n para conversi√≥n segura de encodings\n",
    "def convertir_encoding_seguro(archivo_origen, archivo_destino, encoding_destino='utf-8'):\n",
    "    \"\"\"\n",
    "    Convierte un archivo de un encoding a otro de forma segura.\n",
    "    Incluye validaci√≥n y reporte de problemas.\n",
    "    \"\"\"\n",
    "    print(f\"\\nüîÑ CONVERSI√ìN DE ENCODING\")\n",
    "    print(f\"   Origen: {archivo_origen.name}\")\n",
    "    print(f\"   Destino: {archivo_destino.name}\")\n",
    "    print(f\"   Encoding objetivo: {encoding_destino}\")\n",
    "    \n",
    "    # Paso 1: Leer archivo origen con detecci√≥n autom√°tica\n",
    "    df_origen, encoding_origen = leer_csv_robusto(archivo_origen, mostrar_proceso=False)\n",
    "    print(f\"   üìñ Encoding origen detectado: {encoding_origen}\")\n",
    "    \n",
    "    # Paso 2: Verificar que no hay p√©rdida de datos\n",
    "    caracteres_especiales = ['√°', '√©', '√≠', '√≥', '√∫', '√±', '√Å', '√â', '√ç', '√ì', '√ö', '√ë']\n",
    "    \n",
    "    texto_completo = ' '.join(df_origen.astype(str).values.flatten())\n",
    "    especiales_encontrados = [c for c in caracteres_especiales if c in texto_completo]\n",
    "    \n",
    "    print(f\"   üîç Caracteres especiales encontrados: {especiales_encontrados}\")\n",
    "    \n",
    "    # Paso 3: Realizar conversi√≥n\n",
    "    try:\n",
    "        df_origen.to_csv(archivo_destino, index=False, encoding=encoding_destino)\n",
    "        print(f\"   ‚úÖ Conversi√≥n exitosa\")\n",
    "        \n",
    "        # Paso 4: Verificar conversi√≥n leyendo el archivo convertido\n",
    "        df_verificacion = pd.read_csv(archivo_destino, encoding=encoding_destino)\n",
    "        texto_verificacion = ' '.join(df_verificacion.astype(str).values.flatten())\n",
    "        especiales_despues = [c for c in caracteres_especiales if c in texto_verificacion]\n",
    "        \n",
    "        if set(especiales_encontrados) == set(especiales_despues):\n",
    "            print(f\"   ‚úÖ Verificaci√≥n: No se perdieron caracteres especiales\")\n",
    "            return True\n",
    "        else:\n",
    "            perdidos = set(especiales_encontrados) - set(especiales_despues)\n",
    "            print(f\"   ‚ö†Ô∏è  Advertencia: Se perdieron caracteres: {perdidos}\")\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Error en conversi√≥n: {e}\")\n",
    "        return False\n",
    "\n",
    "# Realizar conversiones de ejemplo\n",
    "print(\"EJEMPLO DE MIGRACI√ìN: Latin1 -> UTF-8\")\n",
    "print(\"(Caso t√≠pico: Sistema legacy -> Sistema moderno)\")\n",
    "\n",
    "archivo_latin1 = DATA_DIR / \"afiliados_latin1.csv\"\n",
    "archivo_convertido = DATA_DIR / \"afiliados_latin1_to_utf8.csv\"\n",
    "\n",
    "exito = convertir_encoding_seguro(archivo_latin1, archivo_convertido, 'utf-8')\n",
    "\n",
    "if exito:\n",
    "    print(\"\\nüéâ ¬°Migraci√≥n exitosa!\")\n",
    "    print(\"üíº En COMFENALCO: As√≠ migrar√≠amos datos hist√≥ricos al nuevo sistema\")\nelse:\n",
    "    print(\"\\n‚ö†Ô∏è  Se requiere revisi√≥n manual\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Manejo robusto de archivos\n",
    "\n",
    "### Contexto Real - Operaci√≥n diaria en COMFENALCO:\n",
    "**Situaci√≥n**: Llegan 20 archivos diarios de diferentes fuentes:\n",
    "- Laboratorios (Latin1)\n",
    "- Farmacias (UTF-8) \n",
    "- Hospitales (CP1252)\n",
    "- MinSalud (UTF-8)\n",
    "- Supersalud (Variable)\n",
    "\n",
    "### ü§î Pregunta reflexiva:\n",
    "**¬øC√≥mo procesar√≠an ustedes 20 archivos diferentes cada d√≠a sin saber su encoding?**\n",
    "\n",
    "### üí° Soluci√≥n: Pipeline autom√°tico robusto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline robusto para procesamiento masivo\n",
    "def procesar_archivos_masivo(carpeta_archivos, carpeta_salida):\n",
    "    \"\"\"\n",
    "    Procesa m√∫ltiples archivos autom√°ticamente.\n",
    "    Esta ser√≠a la funci√≥n que ejecutar√≠amos diariamente en COMFENALCO.\n",
    "    \"\"\"\n",
    "    carpeta_salida.mkdir(exist_ok=True)\n",
    "    \n",
    "    archivos_csv = list(carpeta_archivos.glob(\"*.csv\"))\n",
    "    \n",
    "    print(f\"\\nüè≠ PROCESAMIENTO MASIVO DE ARCHIVOS\")\n",
    "    print(f\"üìÅ Carpeta origen: {carpeta_archivos}\")\n",
    "    print(f\"üìÅ Carpeta destino: {carpeta_salida}\")\n",
    "    print(f\"üìä Archivos encontrados: {len(archivos_csv)}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    resultados = {\n",
    "        'exitosos': [],\n",
    "        'errores': [],\n",
    "        'advertencias': []\n",
    "    }\n",
    "    \n",
    "    for i, archivo in enumerate(archivos_csv, 1):\n",
    "        print(f\"\\n[{i}/{len(archivos_csv)}] Procesando: {archivo.name}\")\n",
    "        \n",
    "        try:\n",
    "            # Leer con detecci√≥n autom√°tica\n",
    "            df, encoding_usado = leer_csv_robusto(archivo, mostrar_proceso=False)\n",
    "            \n",
    "            # Validar datos b√°sicos\n",
    "            filas_vacias = df.isnull().all(axis=1).sum()\n",
    "            cols_vacias = df.isnull().all(axis=0).sum()\n",
    "            \n",
    "            print(f\"   üìã {df.shape[0]} filas, {df.shape[1]} columnas\")\n",
    "            print(f\"   üî§ Encoding: {encoding_usado}\")\n",
    "            \n",
    "            if filas_vacias > 0:\n",
    "                print(f\"   ‚ö†Ô∏è  {filas_vacias} filas completamente vac√≠as\")\n",
    "                resultados['advertencias'].append(f\"{archivo.name}: {filas_vacias} filas vac√≠as\")\n",
    "            \n",
    "            if cols_vacias > 0:\n",
    "                print(f\"   ‚ö†Ô∏è  {cols_vacias} columnas completamente vac√≠as\")\n",
    "                resultados['advertencias'].append(f\"{archivo.name}: {cols_vacias} columnas vac√≠as\")\n",
    "            \n",
    "            # Guardar normalizado en UTF-8\n",
    "            archivo_salida = carpeta_salida / f\"normalizado_{archivo.name}\"\n",
    "            df.to_csv(archivo_salida, index=False, encoding='utf-8')\n",
    "            \n",
    "            print(f\"   ‚úÖ Procesado y guardado como: {archivo_salida.name}\")\n",
    "            resultados['exitosos'].append(archivo.name)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Error: {str(e)}\")\n",
    "            resultados['errores'].append(f\"{archivo.name}: {str(e)}\")\n",
    "    \n",
    "    # Reporte final\n",
    "    print(f\"\\nüìä REPORTE FINAL:\")\n",
    "    print(f\"   ‚úÖ Exitosos: {len(resultados['exitosos'])}\")\n",
    "    print(f\"   ‚ö†Ô∏è  Con advertencias: {len(resultados['advertencias'])}\")\n",
    "    print(f\"   ‚ùå Con errores: {len(resultados['errores'])}\")\n",
    "    \n",
    "    if resultados['errores']:\n",
    "        print(f\"\\n‚ùå ERRORES ENCONTRADOS:\")\n",
    "        for error in resultados['errores']:\n",
    "            print(f\"   ‚Ä¢ {error}\")\n",
    "    \n",
    "    return resultados\n",
    "\n",
    "# Crear carpeta de salida\n",
    "carpeta_normalizados = DATA_DIR / \"normalizados\"\n",
    "\n",
    "# Procesar todos los archivos de ejemplo\n",
    "resultado_proceso = procesar_archivos_masivo(DATA_DIR, carpeta_normalizados)\n",
    "\n",
    "print(\"\\nüíº Aplicaci√≥n en COMFENALCO:\")\n",
    "print(\"   - Este proceso se ejecutar√≠a autom√°ticamente cada d√≠a\")\n",
    "print(\"   - Los archivos normalizados se cargar√≠an a la base de datos\")\n",
    "print(\"   - Los errores se reportar√≠an al equipo t√©cnico\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Casos de error y soluciones\n",
    "\n",
    "### ‚ö†Ô∏è Errores m√°s comunes en sistemas de salud:\n",
    "\n",
    "1. **UnicodeDecodeError**: Archivo con encoding incorrecto\n",
    "2. **Caracteres de reemplazo**: ÔøΩ ÔøΩ ÔøΩ en lugar de acentos\n",
    "3. **P√©rdida de informaci√≥n**: Nombres truncados\n",
    "4. **Inconsistencia**: Mismo paciente con diferentes nombres\n",
    "\n",
    "### ü§î Pregunta reflexiva:\n",
    "**¬øCu√°l de estos errores consideran m√°s grave para la operaci√≥n de una EPS?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulador de errores comunes y sus soluciones\n",
    "def simular_errores_comunes():\n",
    "    \"\"\"\n",
    "    Simula y resuelve errores t√≠picos de encoding en sistemas m√©dicos.\n",
    "    \"\"\"\n",
    "    print(\"üö® SIMULADOR DE ERRORES COMUNES\")\n",
    "    print(\"================================\")\n",
    "    \n",
    "    # Error 1: UnicodeDecodeError\n",
    "    print(\"\\n1. ERROR: UnicodeDecodeError\")\n",
    "    print(\"   Situaci√≥n: Intentar leer archivo Latin1 como UTF-8\")\n",
    "    \n",
    "    archivo_latin1 = DATA_DIR / \"afiliados_latin1.csv\"\n",
    "    \n",
    "    print(\"   ‚ùå Forma incorrecta:\")\n",
    "    try:\n",
    "        # Esto causar√° problemas\n",
    "        df_error = pd.read_csv(archivo_latin1, encoding='utf-8')\n",
    "        print(\"   (No deber√≠a llegar aqu√≠)\")\n",
    "    except UnicodeDecodeError as e:\n",
    "        print(f\"      UnicodeDecodeError: {str(e)[:100]}...\")\n",
    "    \n",
    "    print(\"\\n   ‚úÖ Soluci√≥n correcta:\")\n",
    "    df_correcto, encoding = leer_csv_robusto(archivo_latin1, mostrar_proceso=False)\n",
    "    print(f\"      Archivo le√≠do correctamente con {encoding}\")\n",
    "    print(f\"      Primer nombre: {df_correcto['nombres'].iloc[0]}\")\n",
    "    \n",
    "    # Error 2: Caracteres de reemplazo\n",
    "    print(\"\\n2. ERROR: Caracteres de reemplazo (ÔøΩ)\")\n",
    "    print(\"   Situaci√≥n: Forzar lectura con errors='replace'\")\n",
    "    \n",
    "    print(\"   ‚ùå Resultado problem√°tico:\")\n",
    "    try:\n",
    "        df_reemplazos = pd.read_csv(archivo_latin1, encoding='utf-8', errors='replace')\n",
    "        print(f\"      Nombre con reemplazos: {df_reemplazos['nombres'].iloc[1]}\")\n",
    "        print(\"      üëÄ ¬øNotan los caracteres extra√±os?\")\n",
    "    except Exception as e:\n",
    "        print(f\"      Error: {e}\")\n",
    "    \n",
    "    print(\"\\n   ‚úÖ Soluci√≥n: Usar encoding correcto desde el inicio\")\n",
    "    df_sin_problemas = pd.read_csv(archivo_latin1, encoding='latin1')\n",
    "    print(f\"      Nombre correcto: {df_sin_problemas['nombres'].iloc[1]}\")\n",
    "    \n",
    "    # Error 3: Detecci√≥n incorrecta\n",
    "    print(\"\\n3. PROBLEMA: Detecci√≥n autom√°tica fallida\")\n",
    "    print(\"   Situaci√≥n: chardet detecta mal el encoding\")\n",
    "    \n",
    "    # Crear archivo problem√°tico\n",
    "    texto_problematico = \"Jos√©,Mar√≠a,√Ångel\\n25,30,28\\n\"\n",
    "    archivo_problema = DATA_DIR / \"problema_deteccion.csv\"\n",
    "    \n",
    "    with open(archivo_problema, 'w', encoding='latin1') as f:\n",
    "        f.write(texto_problematico)\n",
    "    \n",
    "    # Detectar (puede fallar)\n",
    "    with open(archivo_problema, 'rb') as f:\n",
    "        muestra = f.read()\n",
    "    deteccion = chardet.detect(muestra)\n",
    "    \n",
    "    print(f\"   üîç chardet detect√≥: {deteccion['encoding']} ({deteccion['confidence']*100:.1f}% confianza)\")\n",
    "    print(f\"   üìù Encoding real: latin1\")\n",
    "    \n",
    "    if deteccion['confidence'] < 0.7:\n",
    "        print(\"   ‚ö†Ô∏è  Baja confianza - requiere verificaci√≥n manual\")\n",
    "    \n",
    "    print(\"\\n   ‚úÖ Soluci√≥n: Pipeline con m√∫ltiples intentos\")\n",
    "    print(\"      1. Usar detecci√≥n autom√°tica si confianza > 70%\")\n",
    "    print(\"      2. Si falla, probar UTF-8\")\n",
    "    print(\"      3. Si falla, probar Latin1\")\n",
    "    print(\"      4. Como √∫ltimo recurso, usar 'replace'\")\n",
    "\n",
    "simular_errores_comunes()\n",
    "\n",
    "# CHECKPOINT 4 - FINAL\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ CHECKPOINT FINAL: Revisi√≥n completa\")\n",
    "print(\"üë®‚Äçüè´ ¬øTodos comprenden los 3 tipos de errores mostrados?\")\n",
    "print(\"ü§î ¬øCu√°l creen que es m√°s com√∫n en su trabajo diario?\")\n",
    "print(\"üíº En COMFENALCO: Estos errores pueden afectar la facturaci√≥n\")\n",
    "print(\"üéØ Objetivo alcanzado: Saben detectar y corregir problemas de encoding\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Implementaci√≥n en sistemas EPS\n",
    "\n",
    "### Contexto Real - Implementaci√≥n pr√°ctica en COMFENALCO:\n",
    "\n",
    "#### üè• Casos de uso espec√≠ficos:\n",
    "1. **RIPS (Reportes integrales)**: Caracteres especiales en diagn√≥sticos\n",
    "2. **BDUA (Base √∫nica de afiliados)**: Nombres con tildes y √±\n",
    "3. **Intercambio con IPS**: Archivos de diferentes sistemas\n",
    "4. **Reportes Supersalud**: Formato estricto UTF-8\n",
    "5. **Facturaci√≥n**: Nombres exactos para validaci√≥n\n",
    "\n",
    "### ü§î Pregunta reflexiva final:\n",
    "**¬øC√≥mo implementar√≠an esto en su flujo de trabajo actual?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clase para implementaci√≥n empresarial\n",
    "class ManejadorEncodingEPS:\n",
    "    \"\"\"\n",
    "    Clase para manejo robusto de encoding en sistemas EPS.\n",
    "    Lista para usar en producci√≥n en COMFENALCO.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, carpeta_logs=None):\n",
    "        self.encodings_comunes = ['utf-8', 'latin1', 'cp1252', 'ascii']\n",
    "        self.carpeta_logs = carpeta_logs or Path('logs')\n",
    "        self.carpeta_logs.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Configurar logging\n",
    "        self.log_procesamiento = []\n",
    "    \n",
    "    def leer_archivo_seguro(self, ruta_archivo):\n",
    "        \"\"\"Lectura robusta con logging detallado.\"\"\"\n",
    "        inicio = datetime.now()\n",
    "        \n",
    "        try:\n",
    "            # Detecci√≥n autom√°tica\n",
    "            with open(ruta_archivo, 'rb') as f:\n",
    "                muestra = f.read(10000)\n",
    "            \n",
    "            deteccion = chardet.detect(muestra)\n",
    "            encoding_detectado = deteccion['encoding']\n",
    "            confianza = deteccion['confidence']\n",
    "            \n",
    "            # Intentar lectura\n",
    "            df = pd.read_csv(ruta_archivo, encoding=encoding_detectado)\n",
    "            \n",
    "            # Log exitoso\n",
    "            log_entry = {\n",
    "                'archivo': ruta_archivo.name,\n",
    "                'timestamp': inicio.isoformat(),\n",
    "                'encoding_detectado': encoding_detectado,\n",
    "                'confianza': confianza,\n",
    "                'filas': df.shape[0],\n",
    "                'columnas': df.shape[1],\n",
    "                'estado': 'EXITOSO',\n",
    "                'tiempo_procesamiento': (datetime.now() - inicio).total_seconds()\n",
    "            }\n",
    "            \n",
    "            self.log_procesamiento.append(log_entry)\n",
    "            return df, log_entry\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Log de error\n",
    "            log_entry = {\n",
    "                'archivo': ruta_archivo.name,\n",
    "                'timestamp': inicio.isoformat(),\n",
    "                'error': str(e),\n",
    "                'estado': 'ERROR',\n",
    "                'tiempo_procesamiento': (datetime.now() - inicio).total_seconds()\n",
    "            }\n",
    "            \n",
    "            self.log_procesamiento.append(log_entry)\n",
    "            raise\n",
    "    \n",
    "    def generar_reporte(self):\n",
    "        \"\"\"Genera reporte de procesamiento para auditor√≠a.\"\"\"\n",
    "        if not self.log_procesamiento:\n",
    "            return \"No hay datos de procesamiento\"\n",
    "        \n",
    "        df_log = pd.DataFrame(self.log_procesamiento)\n",
    "        \n",
    "        reporte = {\n",
    "            'total_archivos': len(df_log),\n",
    "            'exitosos': len(df_log[df_log['estado'] == 'EXITOSO']),\n",
    "            'errores': len(df_log[df_log['estado'] == 'ERROR']),\n",
    "            'tiempo_total': df_log['tiempo_procesamiento'].sum(),\n",
    "            'encodings_detectados': df_log['encoding_detectado'].value_counts().to_dict() if 'encoding_detectado' in df_log.columns else {}\n",
    "        }\n",
    "        \n",
    "        return reporte\n",
    "\n",
    "# Demostrar uso empresarial\n",
    "print(\"üíº IMPLEMENTACI√ìN PARA COMFENALCO\")\n",
    "print(\"=================================\")\n",
    "\n",
    "manejador = ManejadorEncodingEPS()\n",
    "\n",
    "# Procesar archivos con logging\n",
    "archivos_ejemplo = list(DATA_DIR.glob(\"afiliados_*.csv\"))\n",
    "\n",
    "print(f\"Procesando {len(archivos_ejemplo)} archivos con logging empresarial...\\n\")\n",
    "\n",
    "for archivo in archivos_ejemplo:\n",
    "    try:\n",
    "        df, log = manejador.leer_archivo_seguro(archivo)\n",
    "        print(f\"‚úÖ {archivo.name}: {log['filas']} filas, encoding {log['encoding_detectado']}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå {archivo.name}: Error - {str(e)[:50]}...\")\n",
    "\n",
    "# Generar reporte final\n",
    "reporte = manejador.generar_reporte()\n",
    "print(f\"\\nüìä REPORTE DE PROCESAMIENTO:\")\n",
    "for key, value in reporte.items():\n",
    "    print(f\"   {key}: {value}\")\n",
    "\n",
    "print(\"\\nüéØ BENEFICIOS PARA COMFENALCO:\")\n",
    "print(\"   ‚úÖ Procesamiento autom√°tico y confiable\")\n",
    "print(\"   üìã Logs detallados para auditor√≠a\")\n",
    "print(\"   üîç Detecci√≥n temprana de problemas\")\n",
    "print(\"   üìà M√©tricas de calidad de datos\")\n",
    "print(\"   ‚ö° Reducci√≥n de tiempo manual\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Ejercicios pr√°cticos con datos reales\n",
    "\n",
    "### üèÉ‚Äç‚ôÇÔ∏è Ejercicio 1: Detecci√≥n y correcci√≥n\n",
    "**Contexto**: Han llegado 3 archivos de diferentes IPS con problemas de encoding.\n",
    "1. Detecta autom√°ticamente el encoding de cada archivo\n",
    "2. Lee los datos correctamente\n",
    "3. Identifica qu√© nombres tienen problemas\n",
    "4. Genera un reporte de calidad\n",
    "\n",
    "### üèÉ‚Äç‚ôÄÔ∏è Ejercicio 2: Migraci√≥n masiva\n",
    "**Contexto**: Migrar 50 archivos hist√≥ricos de Latin1 a UTF-8.\n",
    "1. Crea una funci√≥n de migraci√≥n por lotes\n",
    "2. Incluye validaci√≥n antes y despu√©s\n",
    "3. Genera reporte de archivos problem√°ticos\n",
    "4. Implementa rollback en caso de errores\n",
    "\n",
    "### üèÉ‚Äç‚ôÇÔ∏è Ejercicio 3: Pipeline de producci√≥n\n",
    "**Contexto**: Crear sistema autom√°tico para COMFENALCO.\n",
    "1. Pipeline que procese archivos diarios autom√°ticamente\n",
    "2. Sistema de alertas para archivos problem√°ticos\n",
    "3. Dashboard con m√©tricas de calidad\n",
    "4. Integraci√≥n con base de datos\n",
    "\n",
    "### üèÉ‚Äç‚ôÄÔ∏è Ejercicio 4: Caso real RIPS\n",
    "**Contexto**: Procesar archivos RIPS con diagn√≥sticos en espa√±ol.\n",
    "1. Manejar c√≥digos CIE-10 con descripci√≥n\n",
    "2. Validar que no se pierdan caracteres especiales\n",
    "3. Generar archivo para Supersalud en UTF-8\n",
    "4. Crear reporte de validaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plantilla para resolver ejercicios\n",
    "def plantilla_ejercicios():\n",
    "    \"\"\"\n",
    "    Espacio para que los participantes resuelvan los ejercicios.\n",
    "    \"\"\"\n",
    "    print(\"‚úçÔ∏è ESPACIO PARA EJERCICIOS PR√ÅCTICOS\")\n",
    "    print(\"====================================\")\n",
    "    \n",
    "    print(\"\\nüèÉ‚Äç‚ôÇÔ∏è Ejercicio 1: Detecci√≥n y correcci√≥n\")\n",
    "    print(\"# Su c√≥digo aqu√≠:\")\n",
    "    print(\"# archivos_problema = [archivo1, archivo2, archivo3]\")\n",
    "    print(\"# for archivo in archivos_problema:\")\n",
    "    print(\"#     encoding, confianza = detectar_encoding_archivo(archivo)\")\n",
    "    \n",
    "    print(\"\\nüèÉ‚Äç‚ôÄÔ∏è Ejercicio 2: Migraci√≥n masiva\")\n",
    "    print(\"# Su c√≥digo aqu√≠:\")\n",
    "    print(\"# def migrar_lote(archivos_origen, carpeta_destino):\")\n",
    "    print(\"#     # Implementar migraci√≥n con validaci√≥n\")\n",
    "    \n",
    "    print(\"\\nüèÉ‚Äç‚ôÇÔ∏è Ejercicio 3: Pipeline de producci√≥n\")\n",
    "    print(\"# Su c√≥digo aqu√≠:\")\n",
    "    print(\"# class PipelineComfenalco:\")\n",
    "    print(\"#     def procesar_diario(self):\")\n",
    "    print(\"#         # Implementar procesamiento autom√°tico\")\n",
    "    \n",
    "    print(\"\\nüèÉ‚Äç‚ôÄÔ∏è Ejercicio 4: Caso real RIPS\")\n",
    "    print(\"# Su c√≥digo aqu√≠:\")\n",
    "    print(\"# def procesar_rips(archivo_entrada, archivo_salida):\")\n",
    "    print(\"#     # Validar diagn√≥sticos CIE-10\")\n",
    "    print(\"#     # Mantener caracteres especiales\")\n",
    "    \n",
    "    # Checklist de verificaci√≥n\n",
    "    checklist = [\n",
    "        \"‚òê Ejercicio 1: Detecci√≥n autom√°tica implementada\",\n",
    "        \"‚òê Ejercicio 2: Migraci√≥n masiva con validaci√≥n\",\n",
    "        \"‚òê Ejercicio 3: Pipeline autom√°tico funcional\",\n",
    "        \"‚òê Ejercicio 4: Procesamiento RIPS validado\"\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\n‚úÖ CHECKLIST DE VERIFICACI√ìN:\")\n",
    "    for item in checklist:\n",
    "        print(f\"   {item}\")\n",
    "    \n",
    "    print(f\"\\nüéØ CRITERIOS DE √âXITO:\")\n",
    "    print(f\"   ‚Ä¢ No se pierden caracteres especiales\")\n",
    "    print(f\"   ‚Ä¢ Manejo robusto de errores\")\n",
    "    print(f\"   ‚Ä¢ Logging adecuado para auditor√≠a\")\n",
    "    print(f\"   ‚Ä¢ Aplicabilidad real en COMFENALCO\")\n",
    "\n",
    "plantilla_ejercicios()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Resumen del Notebook\n",
    "\n",
    "### üéØ Objetivos alcanzados:\n",
    "1. ‚úÖ **Comprensi√≥n profunda** de codificaci√≥n de caracteres\n",
    "2. ‚úÖ **Resoluci√≥n pr√°ctica** de problemas con nombres colombianos\n",
    "3. ‚úÖ **Herramientas robustas** para detecci√≥n autom√°tica\n",
    "4. ‚úÖ **Pipeline empresarial** listo para producci√≥n\n",
    "5. ‚úÖ **Casos de error** y sus soluciones\n",
    "\n",
    "### üè• Aplicaci√≥n directa en COMFENALCO:\n",
    "- **Procesamiento RIPS**: Sin p√©rdida de caracteres especiales\n",
    "- **Intercambio con IPS**: Manejo autom√°tico de diferentes encodings\n",
    "- **Reportes Supersalud**: Formato UTF-8 garantizado\n",
    "- **Migraci√≥n de datos**: Sistema legacy ‚Üí moderno\n",
    "- **Validaci√≥n diaria**: Detecci√≥n temprana de problemas\n",
    "\n",
    "### üîß Herramientas implementadas:\n",
    "- Detector autom√°tico de encoding\n",
    "- Lector robusto de archivos\n",
    "- Convertidor seguro entre formatos\n",
    "- Pipeline de procesamiento masivo\n",
    "- Sistema de logging empresarial\n",
    "\n",
    "### ‚ö†Ô∏è Errores cr√≠ticos prevenidos:\n",
    "- **UnicodeDecodeError**: Archivos no legibles\n",
    "- **Caracteres perdidos**: Nombres truncados\n",
    "- **Datos corruptos**: Informaci√≥n irrecuperable\n",
    "- **Inconsistencias**: Mismo paciente, nombres diferentes\n",
    "\n",
    "### üöÄ Pr√≥ximos pasos:\n",
    "- **M√≥dulo II:** Conexi√≥n avanzada con bases de datos\n",
    "- **M√≥dulo III:** Validaci√≥n y limpieza de datos m√©dicos\n",
    "- **M√≥dulo IV:** Automatizaci√≥n de reportes\n",
    "\n",
    "---\n",
    "\n",
    "**üí° Mensaje clave**: En el sector salud, un nombre mal codificado puede significar un paciente no encontrado. Con estas herramientas, COMFENALCO puede procesar datos de cualquier fuente sin perder informaci√≥n cr√≠tica."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
