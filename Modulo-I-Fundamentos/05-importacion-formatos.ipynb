{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05 ¬∑ Importaci√≥n de datos en diferentes formatos\n",
    "\n",
    "**M√≥dulo I ‚Äî Fundamentos**\n",
    "\n",
    "## Objetivos:\n",
    "- Importar datos desde diferentes formatos: CSV, Excel, JSON, XML\n",
    "- Manejar problemas comunes de importaci√≥n (encodings, separadores, tipos)\n",
    "- Exportar datos procesados a m√∫ltiples formatos\n",
    "- Aplicar t√©cnicas de validaci√≥n y limpieza inicial\n",
    "- Trabajar con APIs y datos web en tiempo real\n",
    "\n",
    "## Requisitos:\n",
    "- pandas, openpyxl, lxml, requests instalados\n",
    "- Conexi√≥n a internet para ejemplos con APIs\n",
    "- Datos de ejemplo (se generar√°n autom√°ticamente)\n",
    "\n",
    "## √çndice:\n",
    "1. Preparaci√≥n del entorno y datos de ejemplo\n",
    "2. Importaci√≥n desde CSV\n",
    "3. Trabajando con archivos Excel\n",
    "4. Manejo de datos JSON\n",
    "5. Procesamiento de archivos XML\n",
    "6. Conexi√≥n con APIs m√©dicas\n",
    "7. Exportaci√≥n a m√∫ltiples formatos\n",
    "8. Ejercicios pr√°cticos con datos m√©dicos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Preparaci√≥n del entorno y datos de ejemplo\n",
    "\n",
    "Primero verificamos las librer√≠as necesarias y creamos datos sint√©ticos para practicar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librer√≠as necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurar pandas para mejor visualizaci√≥n\n",
    "pd.set_option('display.max_columns', 10)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "print(\"üìö Librer√≠as importadas exitosamente\")\n",
    "print(f\"Pandas versi√≥n: {pd.__version__}\")\n",
    "print(f\"NumPy versi√≥n: {np.__version__}\")\n",
    "\n",
    "# Crear estructura de carpetas para datos\n",
    "BASE_DIR = Path.cwd()\n",
    "DATA_DIR = BASE_DIR / \"data\"\n",
    "RAW_DIR = DATA_DIR / \"raw\"\n",
    "PROCESSED_DIR = DATA_DIR / \"processed\"\n",
    "EXAMPLES_DIR = DATA_DIR / \"examples\"\n",
    "\n",
    "for dir_path in [RAW_DIR, PROCESSED_DIR, EXAMPLES_DIR]:\n",
    "    dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"\\nüìÅ Estructura de carpetas creada:\")\n",
    "for dir_path in [RAW_DIR, PROCESSED_DIR, EXAMPLES_DIR]:\n",
    "    print(f\"  ‚úÖ {dir_path.relative_to(BASE_DIR)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar datos sint√©ticos para ejemplos m√©dicos\n",
    "def generar_datos_medicos_sinteticos(n_pacientes=100):\n",
    "    \"\"\"\n",
    "    Genera un dataset sint√©tico de pacientes para practicar importaci√≥n/exportaci√≥n.\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Generar datos base\n",
    "    nombres = [\"Ana\", \"Carlos\", \"Mar√≠a\", \"Luis\", \"Sofia\", \"Pedro\", \"Laura\", \"Miguel\", \"Carmen\", \"Diego\"]\n",
    "    apellidos = [\"Garc√≠a\", \"Rodr√≠guez\", \"L√≥pez\", \"Mart√≠nez\", \"Gonz√°lez\", \"P√©rez\", \"S√°nchez\", \"Ram√≠rez\"]\n",
    "    ciudades = [\"Bogot√°\", \"Medell√≠n\", \"Cali\", \"Barranquilla\", \"Cartagena\"]\n",
    "    tipos_sangre = [\"O+\", \"A+\", \"B+\", \"AB+\", \"O-\", \"A-\", \"B-\", \"AB-\"]\n",
    "    especialidades = [\"Medicina General\", \"Cardiolog√≠a\", \"Neurolog√≠a\", \"Pediatr√≠a\", \"Ginecolog√≠a\"]\n",
    "    \n",
    "    # Generar fechas de consulta en los √∫ltimos 2 a√±os\n",
    "    fecha_inicio = datetime.now() - timedelta(days=730)\n",
    "    fechas_consulta = [fecha_inicio + timedelta(days=np.random.randint(0, 730)) for _ in range(n_pacientes)]\n",
    "    \n",
    "    # Crear dataset\n",
    "    data = {\n",
    "        \"id_paciente\": range(1, n_pacientes + 1),\n",
    "        \"nombre\": np.random.choice(nombres, n_pacientes),\n",
    "        \"apellido\": np.random.choice(apellidos, n_pacientes),\n",
    "        \"edad\": np.random.randint(18, 85, n_pacientes),\n",
    "        \"genero\": np.random.choice([\"M\", \"F\"], n_pacientes),\n",
    "        \"ciudad\": np.random.choice(ciudades, n_pacientes),\n",
    "        \"tipo_sangre\": np.random.choice(tipos_sangre, n_pacientes),\n",
    "        \"peso\": np.round(np.random.normal(70, 15, n_pacientes), 1),\n",
    "        \"altura\": np.round(np.random.normal(170, 10, n_pacientes), 0),\n",
    "        \"presion_sistolica\": np.random.randint(90, 180, n_pacientes),\n",
    "        \"presion_diastolica\": np.random.randint(60, 110, n_pacientes),\n",
    "        \"especialidad_consulta\": np.random.choice(especialidades, n_pacientes),\n",
    "        \"fecha_consulta\": fechas_consulta,\n",
    "        \"costo_consulta\": np.random.randint(80000, 350000, n_pacientes)\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Calcular IMC\n",
    "    df['imc'] = np.round(df['peso'] / (df['altura'] / 100) ** 2, 2)\n",
    "    \n",
    "    # Formatear fecha como string para mejor compatibilidad\n",
    "    df['fecha_consulta'] = df['fecha_consulta'].dt.strftime('%Y-%m-%d')\n",
    "    \n",
    "    print(f\"üìä Dataset sint√©tico generado: {df.shape} pacientes, {df.shape} columnas\")\n",[1]
    "    print(f\"\\nüìã Columnas: {list(df.columns)}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Generar dataset principal\n",
    "df_pacientes = generar_datos_medicos_sinteticos(100)\n",
    "print(f\"\\nüîç Primeras 5 filas:\")\n",
    "display(df_pacientes.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Importaci√≥n desde CSV\n",
    "\n",
    "CSV (Comma Separated Values) es el formato m√°s com√∫n para intercambio de datos tabulares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear diferentes variaciones de CSV para practicar\n",
    "def crear_csvs_ejemplo():\n",
    "    \"\"\"\n",
    "    Crea varios archivos CSV con diferentes caracter√≠sticas para practicar.\n",
    "    \"\"\"\n",
    "    # CSV b√°sico (separado por comas)\n",
    "    csv_basico = EXAMPLES_DIR / \"pacientes_basico.csv\"\n",
    "    df_pacientes.to_csv(csv_basico, index=False)\n",
    "    \n",
    "    # CSV con punto y coma (com√∫n en Excel espa√±ol)\n",
    "    csv_semicolon = EXAMPLES_DIR / \"pacientes_semicolon.csv\"\n",
    "    df_pacientes.to_csv(csv_semicolon, index=False, sep=';')\n",
    "    \n",
    "    # CSV con encoding Latin1 (problemas comunes)\n",
    "    csv_latin1 = EXAMPLES_DIR / \"pacientes_latin1.csv\"\n",
    "    df_pacientes.to_csv(csv_latin1, index=False, encoding='latin1')\n",
    "    \n",
    "    # CSV con datos faltantes simulados\n",
    "    df_con_nan = df_pacientes.copy()\n",
    "    # Simular datos faltantes en algunas columnas\n",
    "    mask_peso = np.random.random(len(df_con_nan)) < 0.1\n",
    "    mask_presion = np.random.random(len(df_con_nan)) < 0.05\n",
    "    df_con_nan.loc[mask_peso, 'peso'] = np.nan\n",
    "    df_con_nan.loc[mask_presion, 'presion_sistolica'] = np.nan\n",
    "    \n",
    "    csv_nan = EXAMPLES_DIR / \"pacientes_con_nan.csv\"\n",
    "    df_con_nan.to_csv(csv_nan, index=False)\n",
    "    \n",
    "    archivos_creados = [\n",
    "        (csv_basico, \"CSV b√°sico (comas, UTF-8)\"),\n",
    "        (csv_semicolon, \"CSV con punto y coma\"),\n",
    "        (csv_latin1, \"CSV con encoding Latin1\"),\n",
    "        (csv_nan, \"CSV con datos faltantes\")\n",
    "    ]\n",
    "    \n",
    "    print(\"üìÑ Archivos CSV creados para pr√°ctica:\")\n",
    "    for archivo, descripcion in archivos_creados:\n",
    "        tama√±o = archivo.stat().st_size / 1024  # KB\n",
    "        print(f\"  ‚úÖ {archivo.name:<25} - {descripcion} ({tama√±o:.1f} KB)\")\n",
    "    \n",
    "    return archivos_creados\n",
    "\n",
    "archivos_csv = crear_csvs_ejemplo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T√©cnicas de importaci√≥n CSV con diferentes par√°metros\n",
    "def demostrar_importacion_csv():\n",
    "    \"\"\"\n",
    "    Demuestra diferentes formas de importar archivos CSV.\n",
    "    \"\"\"\n",
    "    # 1. Importaci√≥n b√°sica\n",
    "    print(\"1Ô∏è‚É£ IMPORTACI√ìN B√ÅSICA:\")\n",
    "    df_basic = pd.read_csv(EXAMPLES_DIR / \"pacientes_basico.csv\")\n",
    "    print(f\"   Forma: {df_basic.shape}\")\n",
    "    print(f\"   Columnas: {list(df_basic.columns)[:5]}...\")  # Primeras 5\n",
    "    print(f\"   Tipos detectados: {dict(df_basic.dtypes.head())}\")  # Primeros 5 tipos\n",
    "    \n",
    "    # 2. CSV con punto y coma\n",
    "    print(f\"\\n2Ô∏è‚É£ CSV CON PUNTO Y COMA:\")\n",
    "    df_semicolon = pd.read_csv(EXAMPLES_DIR / \"pacientes_semicolon.csv\", sep=';')\n",
    "    print(f\"   Forma: {df_semicolon.shape}\")\n",
    "    print(f\"   ¬øDatos iguales al b√°sico? {df_basic.equals(df_semicolon)}\")\n",
    "    \n",
    "    # 3. Manejo de encoding\n",
    "    print(f\"\\n3Ô∏è‚É£ MANEJO DE ENCODING:\")\n",
    "    try:\n",
    "        # Intentar con UTF-8 (fallar√° con Latin1)\n",
    "        df_latin1_utf8 = pd.read_csv(EXAMPLES_DIR / \"pacientes_latin1.csv\")\n",
    "        print(\"   UTF-8: ‚úÖ Funciona\")\n",
    "    except UnicodeDecodeError:\n",
    "        print(\"   UTF-8: ‚ùå Error de encoding\")\n",
    "        # Usar encoding correcto\n",
    "        df_latin1 = pd.read_csv(EXAMPLES_DIR / \"pacientes_latin1.csv\", encoding='latin1')\n",
    "        print(f\"   Latin1: ‚úÖ Funciona - Forma: {df_latin1.shape}\")\n",
    "    \n",
    "    # 4. Datos con valores faltantes\n",
    "    print(f\"\\n4Ô∏è‚É£ DATOS CON VALORES FALTANTES:\")\n",
    "    df_nan = pd.read_csv(EXAMPLES_DIR / \"pacientes_con_nan.csv\")\n",
    "    print(f\"   Forma: {df_nan.shape}\")\n",
    "    print(f\"   Valores nulos por columna:\")\n",
    "    nulos = df_nan.isnull().sum()\n",
    "    for col, count in nulos[nulos > 0].items():\n",
    "        print(f\"     {col}: {count} valores faltantes\")\n",
    "    \n",
    "    # 5. Importaci√≥n con tipos espec√≠ficos\n",
    "    print(f\"\\n5Ô∏è‚É£ ESPECIFICAR TIPOS DE DATOS:\")\n",
    "    tipos_especificos = {\n",
    "        'id_paciente': 'int32',\n",
    "        'edad': 'int16', \n",
    "        'peso': 'float32',\n",
    "        'altura': 'float32',\n",
    "        'genero': 'category',\n",
    "        'ciudad': 'category',\n",
    "        'tipo_sangre': 'category'\n",
    "    }\n",
    "    \n",
    "    df_typed = pd.read_csv(EXAMPLES_DIR / \"pacientes_basico.csv\", dtype=tipos_especificos)\n",
    "    \n",
    "    # Comparar uso de memoria\n",
    "    memoria_original = df_basic.memory_usage(deep=True).sum() / 1024  # KB\n",
    "    memoria_optimizada = df_typed.memory_usage(deep=True).sum() / 1024  # KB\n",
    "    \n",
    "    print(f\"   Memoria original: {memoria_original:.1f} KB\")\n",
    "    print(f\"   Memoria optimizada: {memoria_optimizada:.1f} KB\")\n",
    "    print(f\"   Reducci√≥n: {((memoria_original - memoria_optimizada) / memoria_original * 100):.1f}%\")\n",
    "    \n",
    "    return df_basic, df_nan, df_typed\n",
    "\n",
    "df_csv, df_nan, df_optimizado = demostrar_importacion_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Trabajando con archivos Excel\n",
    "\n",
    "Excel es muy com√∫n en el sector salud para reportes y registros m√©dicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear archivos Excel con m√∫ltiples hojas\n",
    "def crear_excel_ejemplo():\n",
    "    \"\"\"\n",
    "    Crea un archivo Excel con m√∫ltiples hojas simulando un sistema hospitalario.\n",
    "    \"\"\"\n",
    "    excel_path = EXAMPLES_DIR / \"sistema_hospitalario.xlsx\"\n",
    "    \n",
    "    # Hoja 1: Pacientes\n",
    "    df_pacientes_excel = df_pacientes.sample(50).reset_index(drop=True)\n",
    "    \n",
    "    # Hoja 2: Consultas por especialidad\n",
    "    consultas_especialidad = df_pacientes.groupby('especialidad_consulta').agg({\n",
    "        'id_paciente': 'count',\n",
    "        'costo_consulta': ['mean', 'sum'],\n",
    "        'edad': 'mean'\n",
    "    }).round(2)\n",
    "    \n",
    "    # Aplanar nombres de columnas\n",
    "    consultas_especialidad.columns = [\n",
    "        'total_consultas', 'costo_promedio', 'costo_total', 'edad_promedio'\n",
    "    ]\n",
    "    consultas_especialidad = consultas_especialidad.reset_index()\n",
    "    \n",
    "    # Hoja 3: Estad√≠sticas por ciudad\n",
    "    stats_ciudad = df_pacientes.groupby('ciudad').agg({\n",
    "        'id_paciente': 'count',\n",
    "        'edad': ['mean', 'min', 'max'],\n",
    "        'imc': 'mean',\n",
    "        'presion_sistolica': 'mean'\n",
    "    }).round(2)\n",
    "    \n",
    "    # Aplanar nombres de columnas\n",
    "    stats_ciudad.columns = [\n",
    "        'total_pacientes', 'edad_promedio', 'edad_min', 'edad_max', \n",
    "        'imc_promedio', 'presion_promedio'\n",
    "    ]\n",
    "    stats_ciudad = stats_ciudad.reset_index()\n",
    "    \n",
    "    # Escribir archivo Excel\n",
    "    with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:\n",
    "        df_pacientes_excel.to_excel(writer, sheet_name='Pacientes', index=False)\n",
    "        consultas_especialidad.to_excel(writer, sheet_name='Consultas_Especialidad', index=False)\n",
    "        stats_ciudad.to_excel(writer, sheet_name='Estadisticas_Ciudad', index=False)\n",
    "    \n",
    "    print(f\"üìä Archivo Excel creado: {excel_path.name}\")\n",
    "    print(f\"   Hojas: Pacientes ({df_pacientes_excel.shape} filas)\")\n",
    "    print(f\"         Consultas_Especialidad ({consultas_especialidad.shape} filas)\")\n",
    "    print(f\"         Estadisticas_Ciudad ({stats_ciudad.shape} filas)\")\n",
    "    \n",
    "    return excel_path, df_pacientes_excel, consultas_especialidad, stats_ciudad\n",
    "\n",
    "excel_file, df_pac_excel, df_consul, df_stats = crear_excel_ejemplo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T√©cnicas de importaci√≥n desde Excel\n",
    "def demostrar_importacion_excel():\n",
    "    \"\"\"\n",
    "    Demuestra diferentes formas de importar desde archivos Excel.\n",
    "    \"\"\"\n",
    "    excel_path = EXAMPLES_DIR / \"sistema_hospitalario.xlsx\"\n",
    "    \n",
    "    # 1. Leer hoja espec√≠fica\n",
    "    print(\"1Ô∏è‚É£ LEER HOJA ESPEC√çFICA:\")\n",
    "    df_pacientes_leido = pd.read_excel(excel_path, sheet_name='Pacientes')\n",
    "    print(f\"   Hoja 'Pacientes': {df_pacientes_leido.shape}\")\n",
    "    print(f\"   Tipos de datos: {dict(df_pacientes_leido.dtypes.head())}\")\n",
    "    \n",
    "    # 2. Leer todas las hojas\n",
    "    print(f\"\\n2Ô∏è‚É£ LEER TODAS LAS HOJAS:\")\n",
    "    todas_hojas = pd.read_excel(excel_path, sheet_name=None)\n",
    "    print(f\"   Hojas encontradas: {list(todas_hojas.keys())}\")\n",
    "    for nombre, df in todas_hojas.items():\n",
    "        print(f\"   {nombre}: {df.shape} filas, {df.shape} columnas\")\n",[1]
    "    \n",
    "    # 3. Leer rango espec√≠fico\n",
    "    print(f\"\\n3Ô∏è‚É£ LEER RANGO ESPEC√çFICO:\")\n",
    "    df_rango = pd.read_excel(\n",
    "        excel_path, \n",
    "        sheet_name='Pacientes',\n",
    "        usecols=['nombre', 'apellido', 'edad', 'genero', 'ciudad'],\n",
    "        nrows=20\n",
    "    )\n",
    "    print(f\"   Primeros 20 pacientes, 5 columnas: {df_rango.shape}\")\n",
    "    print(f\"   Columnas seleccionadas: {list(df_rango.columns)}\")\n",
    "    \n",
    "    # 4. Manejo de fechas\n",
    "    print(f\"\\n4Ô∏è‚É£ CONVERSI√ìN DE FECHAS:\")\n",
    "    df_fechas = pd.read_excel(\n",
    "        excel_path,\n",
    "        sheet_name='Pacientes', \n",
    "        parse_dates=['fecha_consulta']\n",
    "    )\n",
    "    print(f\"   Tipo de fecha_consulta: {df_fechas['fecha_consulta'].dtype}\")\n",
    "    print(f\"   Ejemplo de fecha: {df_fechas['fecha_consulta'].iloc}\")\n",
    "    \n",
    "    return df_pacientes_leido, todas_hojas, df_rango, df_fechas\n",
    "\n",
    "df_excel, hojas_excel, df_rango_excel, df_fechas_excel = demostrar_importacion_excel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Manejo de datos JSON\n",
    "\n",
    "JSON es muy com√∫n en APIs m√©dicas y sistemas de intercambio de informaci√≥n hospitalaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear diferentes estructuras JSON para practicar\n",
    "def crear_json_ejemplos():\n",
    "    \"\"\"\n",
    "    Crea archivos JSON con diferentes estructuras t√≠picas del sector m√©dico.\n",
    "    \"\"\"\n",
    "    # 1. JSON simple (lista de objetos)\n",
    "    json_simple = EXAMPLES_DIR / \"pacientes_simple.json\"\n",
    "    df_sample = df_pacientes.head(10)\n",
    "    df_sample.to_json(json_simple, orient='records', indent=2)\n",
    "    \n",
    "    # 2. JSON anidado (estructura hospitalaria)\n",
    "    json_anidado = EXAMPLES_DIR / \"hospital_anidado.json\"\n",
    "    estructura_hospital = {\n",
    "        \"hospital\": {\n",
    "            \"nombre\": \"Hospital General COMFENALCO\",\n",
    "            \"nit\": \"890123456-1\",\n",
    "            \"ubicacion\": {\n",
    "                \"ciudad\": \"Cali\",\n",
    "                \"direccion\": \"Calle 25 #15-30\",\n",
    "                \"telefono\": \"(2) 555-0123\"\n",
    "            },\n",
    "            \"departamentos\": [\n",
    "                {\n",
    "                    \"nombre\": \"Cardiolog√≠a\",\n",
    "                    \"jefe\": \"Dr. Carlos Mendoza\",\n",
    "                    \"especialistas\": 5,\n",
    "                    \"consultas_mes\": 450\n",
    "                },\n",
    "                {\n",
    "                    \"nombre\": \"Neurolog√≠a\",\n",
    "                    \"jefe\": \"Dra. Ana Rodr√≠guez\",\n",
    "                    \"especialistas\": 3,\n",
    "                    \"consultas_mes\": 280\n",
    "                },\n",
    "                {\n",
    "                    \"nombre\": \"Pediatr√≠a\",\n",
    "                    \"jefe\": \"Dr. Luis Garc√≠a\", \n",
    "                    \"especialistas\": 4,\n",
    "                    \"consultas_mes\": 380\n",
    "                }\n",
    "            ],\n",
    "            \"pacientes_activos\": df_pacientes.shape,\n",
    "            \"ultima_actualizacion\": datetime.now().isoformat()\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    with open(json_anidado, 'w', encoding='utf-8') as f:\n",
    "        json.dump(estructura_hospital, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    # 3. JSON de resultados de laboratorio\n",
    "    json_laboratorio = EXAMPLES_DIR / \"resultados_laboratorio.json\"\n",
    "    resultados_lab = [\n",
    "        {\n",
    "            \"id_paciente\": 1,\n",
    "            \"fecha_examen\": \"2024-10-01\",\n",
    "            \"tipo_examen\": \"Hemograma completo\",\n",
    "            \"resultados\": {\n",
    "                \"hemoglobina\": {\"valor\": 14.2, \"unidad\": \"g/dL\", \"referencia\": \"12.0-17.5\"},\n",
    "                \"hematocrito\": {\"valor\": 42.5, \"unidad\": \"%\", \"referencia\": \"36-46\"},\n",
    "                \"leucocitos\": {\"valor\": 7200, \"unidad\": \"/mm¬≥\", \"referencia\": \"4000-11000\"},\n",
    "                \"plaquetas\": {\"valor\": 280000, \"unidad\": \"/mm¬≥\", \"referencia\": \"150000-450000\"}\n",
    "            },\n",
    "            \"observaciones\": \"Valores dentro de par√°metros normales\"\n",
    "        },\n",
    "        {\n",
    "            \"id_paciente\": 2,\n",
    "            \"fecha_examen\": \"2024-10-01\", \n",
    "            \"tipo_examen\": \"Perfil lip√≠dico\",\n",
    "            \"resultados\": {\n",
    "                \"colesterol_total\": {\"valor\": 195, \"unidad\": \"mg/dL\", \"referencia\": \"<200\"},\n",
    "                \"hdl\": {\"valor\": 45, \"unidad\": \"mg/dL\", \"referencia\": \">40\"},\n",
    "                \"ldl\": {\"valor\": 125, \"unidad\": \"mg/dL\", \"referencia\": \"<100\"},\n",
    "                \"trigliceridos\": {\"valor\": 150, \"unidad\": \"mg/dL\", \"referencia\": \"<150\"}\n",
    "            },\n",
    "            \"observaciones\": \"LDL ligeramente elevado\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    with open(json_laboratorio, 'w', encoding='utf-8') as f:\n",
    "        json.dump(resultados_lab, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    archivos_json = [\n",
    "        (json_simple, \"JSON simple (lista de pacientes)\"),\n",
    "        (json_anidado, \"JSON anidado (estructura hospitalaria)\"),\n",
    "        (json_laboratorio, \"JSON de resultados de laboratorio\")\n",
    "    ]\n",
    "    \n",
    "    print(\"üìÑ Archivos JSON creados:\")\n",
    "    for archivo, descripcion in archivos_json:\n",
    "        tama√±o = archivo.stat().st_size / 1024  # KB\n",
    "        print(f\"  ‚úÖ {archivo.name:<30} - {descripcion} ({tama√±o:.1f} KB)\")\n",
    "    \n",
    "    return archivos_json\n",
    "\n",
    "# Crear Excel con m√∫ltiples hojas\n",
    "excel_path = EXAMPLES_DIR / \"sistema_hospitalario.xlsx\"\n",
    "with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:\n",
    "    # Hoja principal de pacientes\n",
    "    df_pacientes.head(30).to_excel(writer, sheet_name='Pacientes', index=False)\n",
    "    \n",
    "    # Resumen por especialidad\n",
    "    resumen_esp = df_pacientes.groupby('especialidad_consulta').agg({\n",
    "        'id_paciente': 'count',\n",
    "        'costo_consulta': 'mean',\n",
    "        'edad': 'mean'\n",
    "    }).round(2).reset_index()\n",
    "    resumen_esp.columns = ['especialidad', 'total_pacientes', 'costo_promedio', 'edad_promedio']\n",
    "    resumen_esp.to_excel(writer, sheet_name='Resumen_Especialidades', index=False)\n",
    "\n",
    "print(f\"üìä Archivo Excel creado: {excel_path.name}\")\n",
    "\n",
    "# Crear archivos JSON\n",
    "archivos_json = crear_json_ejemplos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaci√≥n y manejo de archivos JSON\n",
    "def demostrar_importacion_json():\n",
    "    \"\"\"\n",
    "    Demuestra diferentes formas de importar y procesar archivos JSON.\n",
    "    \"\"\"\n",
    "    # 1. JSON simple con pandas\n",
    "    print(\"1Ô∏è‚É£ JSON SIMPLE CON PANDAS:\")\n",
    "    df_json_simple = pd.read_json(EXAMPLES_DIR / \"pacientes_simple.json\")\n",
    "    print(f\"   Forma: {df_json_simple.shape}\")\n",
    "    print(f\"   Columnas: {list(df_json_simple.columns)}\")\n",
    "    \n",
    "    # 2. JSON anidado con biblioteca json\n",
    "    print(f\"\\n2Ô∏è‚É£ JSON ANIDADO CON BIBLIOTECA JSON:\")\n",
    "    with open(EXAMPLES_DIR / \"hospital_anidado.json\", 'r', encoding='utf-8') as f:\n",
    "        hospital_data = json.load(f)\n",
    "    \n",
    "    hospital_info = hospital_data['hospital']\n",
    "    print(f\"   Hospital: {hospital_info['nombre']}\")\n",
    "    print(f\"   Ciudad: {hospital_info['ubicacion']['ciudad']}\")\n",
    "    print(f\"   Departamentos: {len(hospital_info['departamentos'])}\")\n",
    "    \n",
    "    # Convertir departamentos a DataFrame\n",
    "    df_departamentos = pd.DataFrame(hospital_info['departamentos'])\n",
    "    print(f\"   DataFrame departamentos: {df_departamentos.shape}\")\n",
    "    display(df_departamentos)\n",
    "    \n",
    "    # 3. JSON de laboratorio (estructura compleja)\n",
    "    print(f\"\\n3Ô∏è‚É£ JSON DE LABORATORIO (ESTRUCTURA COMPLEJA):\")\n",
    "    with open(EXAMPLES_DIR / \"resultados_laboratorio.json\", 'r', encoding='utf-8') as f:\n",
    "        lab_data = json.load(f)\n",
    "    \n",
    "    # Normalizar JSON anidado\n",
    "    from pandas import json_normalize\n",
    "    \n",
    "    # Normalizar resultados\n",
    "    df_lab_normalizado = json_normalize(lab_data, sep='_')\n",
    "    print(f\"   Datos normalizados: {df_lab_normalizado.shape}\")\n",
    "    print(f\"   Columnas: {list(df_lab_normalizado.columns)[:8]}...\")  # Primeras 8\n",
    "    \n",
    "    # Extraer solo valores num√©ricos de resultados\n",
    "    resultados_numericos = []\n",
    "    for examen in lab_data:\n",
    "        fila = {\n",
    "            'id_paciente': examen['id_paciente'],\n",
    "            'fecha_examen': examen['fecha_examen'],\n",
    "            'tipo_examen': examen['tipo_examen']\n",
    "        }\n",
    "        \n",
    "        # Extraer valores num√©ricos\n",
    "        for prueba, datos in examen['resultados'].items():\n",
    "            fila[f'{prueba}_valor'] = datos['valor']\n",
    "            fila[f'{prueba}_unidad'] = datos['unidad']\n",
    "        \n",
    "        resultados_numericos.append(fila)\n",
    "    \n",
    "    df_lab_limpio = pd.DataFrame(resultados_numericos)\n",
    "    print(f\"\\n   Datos limpios extra√≠dos: {df_lab_limpio.shape}\")\n",
    "    display(df_lab_limpio)\n",
    "    \n",
    "    return df_json_simple, df_departamentos, df_lab_limpio\n",
    "\n",
    "df_json, df_deps, df_lab = demostrar_importacion_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Procesamiento de archivos XML\n",
    "\n",
    "XML es com√∫n en intercambio de informaci√≥n m√©dica estandardizada (HL7, CDA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear archivo XML de ejemplo (historia cl√≠nica)\n",
    "def crear_xml_ejemplo():\n",
    "    \"\"\"\n",
    "    Crea un archivo XML simulando una historia cl√≠nica electr√≥nica.\n",
    "    \"\"\"\n",
    "    xml_content = '''\n",
    "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "<historia_clinica>\n",
    "    <paciente id=\"12345\">\n",
    "        <datos_personales>\n",
    "            <nombre>Juan</nombre>\n",
    "            <apellido>P√©rez Garc√≠a</apellido>\n",
    "            <cedula>10123456789</cedula>\n",
    "            <fecha_nacimiento>1985-03-15</fecha_nacimiento>\n",
    "            <genero>M</genero>\n",
    "            <telefono>300-555-0123</telefono>\n",
    "            <email>juan.perez@email.com</email>\n",
    "        </datos_personales>\n",
    "        <consultas>\n",
    "            <consulta fecha=\"2024-09-15\" especialidad=\"Cardiolog√≠a\">\n",
    "                <motivo>Control de hipertensi√≥n</motivo>\n",
    "                <signos_vitales>\n",
    "                    <presion_arterial sistolica=\"130\" diastolica=\"85\"/>\n",
    "                    <frecuencia_cardiaca>72</frecuencia_cardiaca>\n",
    "                    <temperatura>36.5</temperatura>\n",
    "                    <peso>75</peso>\n",
    "                    <altura>175</altura>\n",
    "                </signos_vitales>\n",
    "                <diagnosticos>\n",
    "                    <diagnostico codigo=\"I10\">Hipertensi√≥n esencial</diagnostico>\n",
    "                </diagnosticos>\n",
    "                <tratamiento>\n",
    "                    <medicamento nombre=\"Losart√°n\" dosis=\"50mg\" frecuencia=\"1 vez al d√≠a\"/>\n",
    "                    <medicamento nombre=\"Hidroclorotiazida\" dosis=\"25mg\" frecuencia=\"1 vez al d√≠a\"/>\n",
    "                </tratamiento>\n",
    "            </consulta>\n",
    "            <consulta fecha=\"2024-08-10\" especialidad=\"Medicina General\">\n",
    "                <motivo>Chequeo rutinario</motivo>\n",
    "                <signos_vitales>\n",
    "                    <presion_arterial sistolica=\"125\" diastolica=\"82\"/>\n",
    "                    <frecuencia_cardiaca>68</frecuencia_cardiaca>\n",
    "                    <temperatura>36.8</temperatura>\n",
    "                    <peso>74</peso>\n",
    "                    <altura>175</altura>\n",
    "                </signos_vitales>\n",
    "                <diagnosticos>\n",
    "                    <diagnostico codigo=\"Z00.0\">Examen m√©dico general</diagnostico>\n",
    "                </diagnosticos>\n",
    "            </consulta>\n",
    "        </consultas>\n",
    "        <examenes_laboratorio>\n",
    "            <examen fecha=\"2024-09-10\" tipo=\"Qu√≠mica sangu√≠nea\">\n",
    "                <resultado nombre=\"Glucosa\" valor=\"95\" unidad=\"mg/dL\" referencia=\"70-100\"/>\n",
    "                <resultado nombre=\"Creatinina\" valor=\"0.9\" unidad=\"mg/dL\" referencia=\"0.7-1.3\"/>\n",
    "                <resultado nombre=\"Colesterol\" valor=\"185\" unidad=\"mg/dL\" referencia=\"<200\"/>\n",
    "            </examen>\n",
    "        </examenes_laboratorio>\n",
    "    </paciente>\n",
    "</historia_clinica>'''\n",
    "    \n",
    "    xml_path = EXAMPLES_DIR / \"historia_clinica.xml\"\n",
    "    with open(xml_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(xml_content.strip())\n",
    "    \n",
    "    print(f\"üìÑ Archivo XML creado: {xml_path.name}\")\n",
    "    print(f\"   Tama√±o: {xml_path.stat().st_size / 1024:.1f} KB\")\n",
    "    \n",
    "    return xml_path\n",
    "\n",
    "xml_file = crear_xml_ejemplo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T√©cnicas de parseo de XML\n",
    "def demostrar_importacion_xml():\n",
    "    \"\"\"\n",
    "    Demuestra c√≥mo extraer datos de archivos XML m√©dicos.\n",
    "    \"\"\"\n",
    "    xml_path = EXAMPLES_DIR / \"historia_clinica.xml\"\n",
    "    \n",
    "    # Parsear XML\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    print(\"1Ô∏è‚É£ INFORMACI√ìN B√ÅSICA DEL XML:\")\n",
    "    print(f\"   Elemento ra√≠z: {root.tag}\")\n",
    "    print(f\"   Elementos hijos: {[child.tag for child in root]}\")\n",
    "    \n",
    "    # Extraer datos del paciente\n",
    "    paciente = root.find('paciente')\n",
    "    datos_personales = paciente.find('datos_personales')\n",
    "    \n",
    "    print(f\"\\n2Ô∏è‚É£ DATOS PERSONALES:\")\n",
    "    info_paciente = {}\n",
    "    for campo in datos_personales:\n",
    "        info_paciente[campo.tag] = campo.text\n",
    "        print(f\"   {campo.tag}: {campo.text}\")\n",
    "    \n",
    "    # Extraer consultas\n",
    "    print(f\"\\n3Ô∏è‚É£ CONSULTAS M√âDICAS:\")\n",
    "    consultas = []\n",
    "    for consulta in paciente.find('consultas').findall('consulta'):\n",
    "        consulta_info = {\n",
    "            'fecha': consulta.get('fecha'),\n",
    "            'especialidad': consulta.get('especialidad'),\n",
    "            'motivo': consulta.find('motivo').text\n",
    "        }\n",
    "        \n",
    "        # Signos vitales\n",
    "        signos = consulta.find('signos_vitales')\n",
    "        if signos is not None:\n",
    "            presion = signos.find('presion_arterial')\n",
    "            if presion is not None:\n",
    "                consulta_info['presion_sistolica'] = int(presion.get('sistolica'))\n",
    "                consulta_info['presion_diastolica'] = int(presion.get('diastolica'))\n",
    "            \n",
    "            for signo in ['frecuencia_cardiaca', 'temperatura', 'peso', 'altura']:\n",
    "                elemento = signos.find(signo)\n",
    "                if elemento is not None:\n",
    "                    consulta_info[signo] = float(elemento.text)\n",
    "        \n",
    "        consultas.append(consulta_info)\n",
    "        print(f\"   {consulta_info['fecha']} - {consulta_info['especialidad']}: {consulta_info['motivo']}\")\n",
    "    \n",
    "    # Convertir consultas a DataFrame\n",
    "    df_consultas = pd.DataFrame(consultas)\n",
    "    print(f\"\\n   DataFrame de consultas: {df_consultas.shape}\")\n",
    "    display(df_consultas)\n",
    "    \n",
    "    # Extraer ex√°menes de laboratorio\n",
    "    print(f\"\\n4Ô∏è‚É£ EX√ÅMENES DE LABORATORIO:\")\n",
    "    examenes = []\n",
    "    examenes_lab = paciente.find('examenes_laboratorio')\n",
    "    if examenes_lab is not None:\n",
    "        for examen in examenes_lab.findall('examen'):\n",
    "            examen_base = {\n",
    "                'fecha': examen.get('fecha'),\n",
    "                'tipo': examen.get('tipo')\n",
    "            }\n",
    "            \n",
    "            for resultado in examen.findall('resultado'):\n",
    "                examen_info = examen_base.copy()\n",
    "                examen_info.update({\n",
    "                    'prueba': resultado.get('nombre'),\n",
    "                    'valor': float(resultado.get('valor')),\n",
    "                    'unidad': resultado.get('unidad'),\n",
    "                    'referencia': resultado.get('referencia')\n",
    "                })\n",
    "                examenes.append(examen_info)\n",
    "    \n",
    "    df_examenes = pd.DataFrame(examenes)\n",
    "    print(f\"   DataFrame de ex√°menes: {df_examenes.shape}\")\n",
    "    display(df_examenes)\n",
    "    \n",
    "    return df_consultas, df_examenes, info_paciente\n",
    "\n",
    "df_consultas_xml, df_examenes_xml, paciente_info = demostrar_importacion_xml()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Conexi√≥n con APIs m√©dicas\n",
    "\n",
    "Muchos sistemas de salud exponen APIs para intercambio de informaci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simular API m√©dica con datos sint√©ticos\n",
    "def simular_api_medica():\n",
    "    \"\"\"\n",
    "    Simula una API m√©dica generando datos en tiempo real.\n",
    "    \"\"\"\n",
    "    import time\n",
    "    import random\n",
    "    \n",
    "    # Simular endpoint de signos vitales en tiempo real\n",
    "    def generar_signos_vitales():\n",
    "        return {\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"id_paciente\": random.randint(1, 100),\n",
    "            \"presion_sistolica\": random.randint(100, 140),\n",
    "            \"presion_diastolica\": random.randint(60, 90),\n",
    "            \"frecuencia_cardiaca\": random.randint(60, 100),\n",
    "            \"temperatura\": round(random.uniform(36.0, 37.5), 1),\n",
    "            \"saturacion_oxigeno\": random.randint(95, 100)\n",
    "        }\n",
    "    \n",
    "    print(\"üåê SIMULANDO API DE SIGNOS VITALES:\")\n",
    "    print(\"   Generando lecturas cada 2 segundos...\\n\")\n",
    "    \n",
    "    # Generar 5 lecturas simuladas\n",
    "    lecturas = []\n",
    "    for i in range(5):\n",
    "        lectura = generar_signos_vitales()\n",
    "        lecturas.append(lectura)\n",
    "        print(f\"   üìä Lectura {i+1}: Paciente {lectura['id_paciente']} - \"\n",
    "              f\"PA: {lectura['presion_sistolica']}/{lectura['presion_diastolica']}, \"\n",
    "              f\"FC: {lectura['frecuencia_cardiaca']}, \"\n",
    "              f\"Temp: {lectura['temperatura']}¬∞C\")\n",
    "        time.sleep(0.5)  # Simular delay de API\n",
    "    \n",
    "    # Convertir a DataFrame\n",
    "    df_api = pd.DataFrame(lecturas)\n",
    "    df_api['timestamp'] = pd.to_datetime(df_api['timestamp'])\n",
    "    \n",
    "    print(f\"\\nüìà DataFrame de API creado: {df_api.shape}\")\n",
    "    display(df_api)\n",
    "    \n",
    "    # Guardar datos de API\n",
    "    api_path = EXAMPLES_DIR / \"datos_api_signos_vitales.json\"\n",
    "    df_api.to_json(api_path, orient='records', date_format='iso', indent=2)\n",
    "    print(f\"\\nüíæ Datos de API guardados en: {api_path.name}\")\n",
    "    \n",
    "    return df_api, api_path\n",
    "\n",
    "df_api_signos, api_file = simular_api_medica()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de conexi√≥n a API p√∫blica (JSONPlaceholder para demostraci√≥n)\n",
    "def demostrar_api_publica():\n",
    "    \"\"\"\n",
    "    Demuestra c√≥mo conectarse a una API p√∫blica y procesar los datos.\n",
    "    \"\"\"\n",
    "    print(\"üåç CONECTANDO A API P√öBLICA DE EJEMPLO:\")\n",
    "    \n",
    "    try:\n",
    "        # Usar JSONPlaceholder como ejemplo (API de prueba gratuita)\n",
    "        url = \"https://jsonplaceholder.typicode.com/users\"\n",
    "        \n",
    "        print(f\"   URL: {url}\")\n",
    "        print(\"   Realizando petici√≥n...\")\n",
    "        \n",
    "        response = requests.get(url, timeout=10)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            print(f\"   ‚úÖ Respuesta exitosa (Status: {response.status_code})\")\n",
    "            \n",
    "            # Convertir a JSON\n",
    "            users_data = response.json()\n",
    "            print(f\"   üìä Datos recibidos: {len(users_data)} registros\")\n",
    "            \n",
    "            # Normalizar JSON anidado\n",
    "            df_users = pd.json_normalize(users_data)\n",
    "            \n",
    "            print(f\"   üìà DataFrame creado: {df_users.shape}\")\n",
    "            print(f\"   Columnas: {list(df_users.columns)[:10]}...\")  # Primeras 10\n",
    "            \n",
    "            # Mostrar algunos datos\n",
    "            print(f\"\\n   üîç Ejemplo de datos:\")\n",
    "            display(df_users[['name', 'email', 'address.city', 'company.name']].head(3))\n",
    "            \n",
    "            # Guardar datos de API\n",
    "            api_users_path = EXAMPLES_DIR / \"datos_api_users.csv\"\n",
    "            df_users.to_csv(api_users_path, index=False)\n",
    "            print(f\"\\nüíæ Datos guardados en: {api_users_path.name}\")\n",
    "            \n",
    "            return df_users\n",
    "            \n",
    "        else:\n",
    "            print(f\"   ‚ùå Error en la petici√≥n (Status: {response.status_code})\")\n",
    "            return None\n",
    "            \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"   ‚ùå Error de conexi√≥n: {e}\")\n",
    "        print(\"   üí° Verifica tu conexi√≥n a internet\")\n",
    "        return None\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Error inesperado: {e}\")\n",
    "        return None\n",
    "\n",
    "df_api_publica = demostrar_api_publica()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Exportaci√≥n a m√∫ltiples formatos\n",
    "\n",
    "Una vez procesados los datos, necesitamos exportarlos para compartir o archivar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar datos a diferentes formatos\n",
    "def demostrar_exportacion_formatos():\n",
    "    \"\"\"\n",
    "    Demuestra c√≥mo exportar datos a diferentes formatos.\n",
    "    \"\"\"\n",
    "    # Usar datos de pacientes para exportar\n",
    "    df_export = df_pacientes.copy()\n",
    "    \n",
    "    print(\"üì§ EXPORTANDO A DIFERENTES FORMATOS:\\n\")\n",
    "    \n",
    "    # 1. CSV con diferentes configuraciones\n",
    "    print(\"1Ô∏è‚É£ EXPORTACI√ìN A CSV:\")\n",
    "    \n",
    "    # CSV est√°ndar\n",
    "    csv_standard = PROCESSED_DIR / \"pacientes_exportado.csv\"\n",
    "    df_export.to_csv(csv_standard, index=False)\n",
    "    print(f\"   ‚úÖ CSV est√°ndar: {csv_standard.name}\")\n",
    "    \n",
    "    # CSV con punto y coma (para Excel espa√±ol)\n",
    "    csv_excel_esp = PROCESSED_DIR / \"pacientes_excel_es.csv\"\n",
    "    df_export.to_csv(csv_excel_esp, index=False, sep=';', decimal=',')\n",
    "    print(f\"   ‚úÖ CSV para Excel ES: {csv_excel_esp.name}\")\n",
    "    \n",
    "    # CSV solo con columnas espec√≠ficas\n",
    "    columnas_resumen = ['id_paciente', 'nombre', 'apellido', 'edad', 'genero', 'imc']\n",
    "    csv_resumen = PROCESSED_DIR / \"pacientes_resumen.csv\"\n",
    "    df_export[columnas_resumen].to_csv(csv_resumen, index=False)\n",
    "    print(f\"   ‚úÖ CSV resumen: {csv_resumen.name} ({len(columnas_resumen)} columnas)\")\n",
    "    \n",
    "    # 2. Excel con formato y m√∫ltiples hojas\n",
    "    print(f\"\\n2Ô∏è‚É£ EXPORTACI√ìN A EXCEL:\")\n",
    "    excel_export = PROCESSED_DIR / \"reporte_pacientes.xlsx\"\n",
    "    \n",
    "    with pd.ExcelWriter(excel_export, engine='openpyxl') as writer:\n",
    "        # Hoja principal\n",
    "        df_export.to_excel(writer, sheet_name='Todos_Pacientes', index=False)\n",
    "        \n",
    "        # Hoja por g√©nero\n",
    "        df_masculino = df_export[df_export['genero'] == 'M']\n",
    "        df_femenino = df_export[df_export['genero'] == 'F']\n",
    "        df_masculino.to_excel(writer, sheet_name='Pacientes_Masculinos', index=False)\n",
    "        df_femenino.to_excel(writer, sheet_name='Pacientes_Femeninos', index=False)\n",
    "        \n",
    "        # Hoja de estad√≠sticas\n",
    "        stats = df_export.groupby('ciudad').agg({\n",
    "            'id_paciente': 'count',\n",
    "            'edad': ['mean', 'min', 'max'],\n",
    "            'imc': 'mean',\n",
    "            'costo_consulta': 'mean'\n",
    "        }).round(2)\n",
    "        stats.columns = ['total_pacientes', 'edad_prom', 'edad_min', 'edad_max', 'imc_prom', 'costo_prom']\n",
    "        stats.reset_index().to_excel(writer, sheet_name='Estadisticas', index=False)\n",
    "    \n",
    "    print(f\"   ‚úÖ Excel completo: {excel_export.name}\")\n",
    "    print(f\"       - Todos_Pacientes: {df_export.shape} filas\")\n",
    "    print(f\"       - Pacientes_Masculinos: {df_masculino.shape} filas\")\n",
    "    print(f\"       - Pacientes_Femeninos: {df_femenino.shape} filas\")\n",
    "    print(f\"       - Estadisticas: {len(df_export['ciudad'].unique())} ciudades\")\n",
    "    \n",
    "    # 3. JSON con diferentes orientaciones\n",
    "    print(f\"\\n3Ô∏è‚É£ EXPORTACI√ìN A JSON:\")\n",
    "    \n",
    "    # JSON records (lista de objetos)\n",
    "    json_records = PROCESSED_DIR / \"pacientes_records.json\"\n",
    "    df_export.head(10).to_json(json_records, orient='records', indent=2)\n",
    "    print(f\"   ‚úÖ JSON records: {json_records.name}\")\n",
    "    \n",
    "    # JSON con estructura anidada por ciudad\n",
    "    json_ciudades = PROCESSED_DIR / \"pacientes_por_ciudad.json\"\n",
    "    datos_por_ciudad = {}\n",
    "    for ciudad in df_export['ciudad'].unique():\n",
    "        datos_ciudad = df_export[df_export['ciudad'] == ciudad].head(5)\n",
    "        datos_por_ciudad[ciudad] = datos_ciudad.to_dict('records')\n",
    "    \n",
    "    with open(json_ciudades, 'w', encoding='utf-8') as f:\n",
    "        json.dump(datos_por_ciudad, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"   ‚úÖ JSON por ciudades: {json_ciudades.name}\")\n",
    "    \n",
    "    # 4. Parquet (formato eficiente)\n",
    "    print(f\"\\n4Ô∏è‚É£ EXPORTACI√ìN A PARQUET:\")\n",
    "    try:\n",
    "        parquet_path = PROCESSED_DIR / \"pacientes.parquet\"\n",
    "        df_export.to_parquet(parquet_path, index=False)\n",
    "        \n",
    "        # Comparar tama√±os\n",
    "        csv_size = csv_standard.stat().st_size / 1024\n",
    "        parquet_size = parquet_path.stat().st_size / 1024\n",
    "        \n",
    "        print(f\"   ‚úÖ Parquet: {parquet_path.name}\")\n",
    "        print(f\"   üìä Comparaci√≥n de tama√±os:\")\n",
    "        print(f\"       CSV: {csv_size:.1f} KB\")\n",
    "        print(f\"       Parquet: {parquet_size:.1f} KB\")\n",
    "        print(f\"       Compresi√≥n: {((csv_size - parquet_size) / csv_size * 100):.1f}%\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Error con Parquet: {e}\")\n",
    "        print(f\"   üí° Instala pyarrow: pip install pyarrow\")\n",
    "    \n",
    "    # Resumen de archivos exportados\n",
    "    archivos_exportados = [\n",
    "        csv_standard, csv_excel_esp, csv_resumen,\n",
    "        excel_export, json_records, json_ciudades\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\nüìã RESUMEN DE EXPORTACIONES:\")\n",
    "    for archivo in archivos_exportados:\n",
    "        if archivo.exists():\n",
    "            tama√±o = archivo.stat().st_size / 1024\n",
    "            print(f\"   üìÑ {archivo.name:<30} ({tama√±o:.1f} KB)\")\n",
    "    \n",
    "    return archivos_exportados\n",
    "\n",
    "archivos_exportados = demostrar_exportacion_formatos()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Ejercicios pr√°cticos con datos m√©dicos\n",
    "\n",
    "### üèÉ‚Äç‚ôÇÔ∏è Ejercicio 1: Importar y validar CSV\n",
    "1. Importa el archivo \"pacientes_con_nan.csv\"\n",
    "2. Identifica columnas con valores faltantes\n",
    "3. Calcula el porcentaje de completitud por columna\n",
    "4. Crea un reporte de calidad de datos\n",
    "\n",
    "### üèÉ‚Äç‚ôÄÔ∏è Ejercicio 2: Procesar Excel con m√∫ltiples hojas\n",
    "1. Importa todas las hojas del archivo \"sistema_hospitalario.xlsx\"\n",
    "2. Combina los datos de diferentes hojas en un solo DataFrame\n",
    "3. Calcula estad√≠sticas consolidadas\n",
    "4. Exporta el resultado a un nuevo Excel\n",
    "\n",
    "### üèÉ‚Äç‚ôÇÔ∏è Ejercicio 3: Transformar JSON a formato tabular\n",
    "1. Importa \"resultados_laboratorio.json\"\n",
    "2. Convierte la estructura anidada a formato tabular\n",
    "3. Crea una tabla con una fila por resultado de laboratorio\n",
    "4. Exporta como CSV para an√°lisis posterior\n",
    "\n",
    "### üèÉ‚Äç‚ôÄÔ∏è Ejercicio 4: Crear pipeline de importaci√≥n\n",
    "1. Crea una funci√≥n que importe datos desde cualquier formato (CSV, Excel, JSON)\n",
    "2. La funci√≥n debe detectar autom√°ticamente el formato\n",
    "3. Aplica validaciones b√°sicas (tipos de datos, valores faltantes)\n",
    "4. Retorna un reporte de importaci√≥n con estad√≠sticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Espacio para resolver ejercicios\n",
    "def resolver_ejercicios():\n",
    "    \"\"\"\n",
    "    Plantilla para resolver los ejercicios propuestos.\n",
    "    \"\"\"\n",
    "    print(\"‚úçÔ∏è ESPACIO PARA RESOLVER EJERCICIOS:\\n\")\n",
    "    \n",
    "    # Ejercicio 1: Validar CSV con NaN\n",
    "    print(\"üèÉ‚Äç‚ôÇÔ∏è Ejercicio 1: Importar y validar CSV\")\n",
    "    print(\"   # Tu c√≥digo aqu√≠\")\n",
    "    print(\"   # df_nan = pd.read_csv(EXAMPLES_DIR / 'pacientes_con_nan.csv')\")\n",
    "    print(\"   # calidad_datos = df_nan.isnull().sum()\")\n",
    "    \n",
    "    print(f\"\\nüèÉ‚Äç‚ôÄÔ∏è Ejercicio 2: Procesar Excel con m√∫ltiples hojas\")\n",
    "    print(\"   # Tu c√≥digo aqu√≠\")\n",
    "    print(\"   # todas_hojas = pd.read_excel('sistema_hospitalario.xlsx', sheet_name=None)\")\n",
    "    \n",
    "    print(f\"\\nüèÉ‚Äç‚ôÇÔ∏è Ejercicio 3: Transformar JSON a formato tabular\")\n",
    "    print(\"   # Tu c√≥digo aqu√≠\")\n",
    "    print(\"   # with open('resultados_laboratorio.json', 'r') as f:\")\n",
    "    print(\"   #     data = json.load(f)\")\n",
    "    \n",
    "    print(f\"\\nüèÉ‚Äç‚ôÄÔ∏è Ejercicio 4: Pipeline de importaci√≥n\")\n",
    "    print(\"   # Tu c√≥digo aqu√≠\")\n",
    "    print(\"   # def importar_datos(archivo):\")\n",
    "    print(\"   #     # detectar formato\")\n",
    "    print(\"   #     # importar seg√∫n formato\")\n",
    "    print(\"   #     # validar datos\")\n",
    "    print(\"   #     # retornar reporte\")\n",
    "    \n",
    "    # Checklist de verificaci√≥n\n",
    "    checklist = [\n",
    "        \"‚òê Ejercicio 1: CSV con NaN importado y analizado\",\n",
    "        \"‚òê Ejercicio 2: Excel multi-hoja procesado\", \n",
    "        \"‚òê Ejercicio 3: JSON transformado a tabla\",\n",
    "        \"‚òê Ejercicio 4: Pipeline de importaci√≥n creado\"\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\n‚úÖ CHECKLIST DE VERIFICACI√ìN:\")\n",
    "    for item in checklist:\n",
    "        print(f\"   {item}\")\n",
    "\n",
    "resolver_ejercicios()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Resumen del Notebook\n",
    "\n",
    "En este notebook hemos dominado la importaci√≥n de datos en Python:\n",
    "\n",
    "### üéØ Formatos cubiertos:\n",
    "1. ‚úÖ **CSV**: Separadores, encodings, tipos de datos, valores faltantes\n",
    "2. ‚úÖ **Excel**: M√∫ltiples hojas, rangos espec√≠ficos, formateo\n",
    "3. ‚úÖ **JSON**: Estructuras simples y anidadas, normalizaci√≥n\n",
    "4. ‚úÖ **XML**: Parseo, extracci√≥n de datos m√©dicos estructurados\n",
    "5. ‚úÖ **APIs**: Conexi√≥n, procesamiento, almacenamiento\n",
    "6. ‚úÖ **Parquet**: Formato eficiente para grandes vol√∫menes\n",
    "\n",
    "### üõ†Ô∏è T√©cnicas aprendidas:\n",
    "- Manejo de diferentes encodings (UTF-8, Latin1)\n",
    "- Optimizaci√≥n de tipos de datos para memoria\n",
    "- Normalizaci√≥n de JSON anidados\n",
    "- Parseo de XML con ElementTree\n",
    "- Conexi√≥n a APIs con requests\n",
    "- Exportaci√≥n con configuraciones espec√≠ficas\n",
    "\n",
    "### üè• Aplicaciones m√©dicas:\n",
    "- **Registros de pacientes** desde sistemas hospitalarios\n",
    "- **Resultados de laboratorio** en formato XML est√°ndar\n",
    "- **APIs de signos vitales** en tiempo real\n",
    "- **Reportes epidemiol√≥gicos** en Excel multi-hoja\n",
    "- **Intercambio de datos** entre sistemas de salud\n",
    "\n",
    "### üìä Archivos generados:\n",
    "- CSV en diferentes formatos y encodings\n",
    "- Excel con m√∫ltiples hojas y an√°lisis\n",
    "- JSON simples y estructurados\n",
    "- XML de historia cl√≠nica\n",
    "- Datos de APIs simuladas\n",
    "\n",
    "### üöÄ Pr√≥ximos pasos:\n",
    "- **M√≥dulo II:** Conexi√≥n y gesti√≥n de bases de datos\n",
    "- **M√≥dulo III:** An√°lisis exploratorio y limpieza de datos\n",
    "- **M√≥dulo IV:** Visualizaci√≥n y reportes automatizados\n",
    "\n",
    "---\n",
    "\n",
    "**üí° ¬°Dominar la importaci√≥n de datos es fundamental para cualquier proyecto de an√°lisis! Con estas t√©cnicas podr√°s trabajar con datos de cualquier sistema m√©dico o hospitalario.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
